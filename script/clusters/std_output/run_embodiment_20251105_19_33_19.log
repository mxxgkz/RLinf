python /home/guo/RL/RLinf/examples/embodiment/train_embodied_agent.py --config-path /home/guo/RL/RLinf/examples/embodiment/config/ --config-name maniskill_ppo_openvla_quickstart runner.logger.log_path=/home/guo/RL/RLinf/logs/20251105-19:33:19
/home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'maniskill_ppo_openvla_quickstart': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
2025-11-05 19:33:49,917	INFO worker.py:1908 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[INFO 19:33:52 RLinf] RLinf is running on a cluster with 1 node and 2 accelerators. The nodes' details are: [NodeInfo(node_rank=0, ray_id='dfb8e2c4d62f9659be4350c8e18c0abf4a2b8d2a0658ac4b97db8b78', node_ip='129.105.2.160', accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, num_accelerators=2, num_cpus=256)]
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
{
  "env": {
    "train": {
      "simulator_type": "maniskill",
      "auto_reset": true,
      "ignore_terminations": true,
      "use_rel_reward": true,
      "seed": 0,
      "num_group": 8,
      "group_size": 1,
      "use_fixed_reset_state_ids": false,
      "max_episode_steps": 80,
      "num_envs": 8,
      "only_eval": false,
      "video_cfg": {
        "save_video": false,
        "info_on_video": true,
        "video_base_dir": "/home/guo/RL/RLinf/logs/20251105-19:33:19/video/train"
      },
      "init_params": {
        "id": "PutCarrotOnPlateInScene-v2",
        "num_envs": 8,
        "obs_mode": "rgb+segmentation",
        "control_mode": "arm_pd_ee_target_delta_pose_align2_gripper_pd_joint_pos",
        "sim_backend": "gpu",
        "sim_config": {
          "sim_freq": 500,
          "control_freq": 5
        },
        "max_episode_steps": 80,
        "sensor_configs": {
          "shader_pack": "default"
        },
        "render_mode": "all"
      }
    },
    "eval": {
      "simulator_type": "maniskill",
      "auto_reset": true,
      "ignore_terminations": true,
      "use_rel_reward": true,
      "seed": 0,
      "num_group": 8,
      "group_size": 1,
      "use_fixed_reset_state_ids": true,
      "num_envs": 8,
      "only_eval": true,
      "video_cfg": {
        "save_video": true,
        "info_on_video": true,
        "video_base_dir": "/home/guo/RL/RLinf/logs/20251105-19:33:19/video/eval"
      },
      "init_params": {
        "id": "PutCarrotOnPlateInScene-v2",
        "num_envs": 8,
        "obs_mode": "rgb+segmentation",
        "control_mode": "arm_pd_ee_target_delta_pose_align2_gripper_pd_joint_pos",
        "sim_backend": "gpu",
        "sim_config": {
          "sim_freq": 500,
          "control_freq": 5
        },
        "max_episode_steps": 80,
        "sensor_configs": {
          "shader_pack": "default"
        },
        "render_mode": null
      }
    },
    "group_name": "EnvGroup",
    "channel": {
      "name": "env_buffer_list",
      "queue_name": "obs_buffer",
      "queue_size": 0
    },
    "enable_offload": false
  },
  "cluster": {
    "num_nodes": 1,
    "component_placement": {
      "actor,env,rollout": "0-1"
    }
  },
  "runner": {
    "task_type": "embodied",
    "logger": {
      "log_path": "/home/guo/RL/RLinf/logs/20251105-19:33:19",
      "project_name": "rlinf",
      "experiment_name": "test_openvla",
      "logger_backends": [
        "tensorboard"
      ]
    },
    "max_epochs": 1000,
    "max_steps": -1,
    "only_eval": false,
    "val_check_interval": -1,
    "save_interval": 40,
    "seq_length": 4096,
    "max_prompt_length": 30
  },
  "algorithm": {
    "auto_reset": true,
    "ignore_terminations": true,
    "use_fixed_reset_state_ids": false,
    "normalize_advantages": true,
    "kl_penalty": "kl",
    "group_size": 1,
    "n_chunk_steps": 80,
    "n_eval_chunk_steps": 80,
    "rollout_micro_batch_size": 64,
    "num_group_envs": 8,
    "rollout_epoch": 1,
    "reward_type": "action_level",
    "logprob_type": "action_level",
    "entropy_type": "action_level",
    "logprob_forward_micro_batch_size": 16,
    "adv_type": "gae",
    "loss_type": "actor_critic",
    "loss_agg_func": "token-mean",
    "kl_beta": 0.0,
    "ratio_clip_eps": 0.2,
    "entropy_bonus": 0,
    "clip_ratio_high": 0.2,
    "clip_ratio_low": 0.2,
    "clip_ratio_c": 3.0,
    "value_clip": 0.2,
    "huber_delta": 10.0,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "sampling_params": {
      "use_greedy": false,
      "temperature_train": 1.0,
      "temperature_eval": 0.6,
      "top_k": 50,
      "top_p": 1.0,
      "repetition_penalty": 1.0
    },
    "length_params": {
      "max_new_token": 7,
      "max_length": 1024,
      "min_length": 1
    }
  },
  "rollout": {
    "group_name": "RolloutGroup",
    "channel": {
      "name": "env_buffer_list",
      "queue_name": "action_buffer",
      "queue_size": 0
    },
    "mode": "colocate",
    "backend": "huggingface",
    "model_dir": "./pre_trained_model/openvla-7b-rlvla-warmup/",
    "gpu_memory_utilization": 0.5,
    "enforce_eager": true,
    "enable_offload": false,
    "pipeline_stage_num": 2
  },
  "actor": {
    "group_name": "ActorGroup",
    "channel": {
      "name": "env_buffer_list",
      "queue_name": "replay_buffer",
      "queue_size": 0
    },
    "training_backend": "fsdp",
    "checkpoint_load_path": "./pre_trained_model/openvla-7b-rlvla-warmup/",
    "checkpoint_save_path": "../results",
    "micro_batch_size": 20,
    "global_batch_size": 160,
    "seed": 1234,
    "enable_offload": false,
    "tokenizer": {
      "tokenizer_type": "HuggingFaceTokenizer",
      "tokenizer_model": "./pre_trained_model/openvla-7b-rlvla-warmup/",
      "extra_vocab_size": 421,
      "use_fast": false,
      "trust_remote_code": true,
      "padding_side": "right"
    },
    "model": {
      "model_name": "openvla",
      "action_dim": 7,
      "num_action_chunks": 1,
      "use_proprio": false,
      "unnorm_key": "bridge_orig",
      "micro_batch_size": 1,
      "val_micro_batch_size": 8,
      "center_crop": true,
      "do_sample": false,
      "precision": "bf16",
      "add_bias_linear": false,
      "add_qkv_bias": true,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "policy_setup": "widowx_bridge",
      "add_value_head": true,
      "image_size": [
        224,
        224
      ],
      "is_lora": true,
      "lora_rank": 32,
      "ckpt_path": null,
      "use_wrist_image": false,
      "attn_implementation": "flash_attention_2",
      "low_cpu_mem_usage": true,
      "trust_remote_code": true,
      "gradient_checkpointing": false,
      "sharding_strategy": "full_shard"
    },
    "optim": {
      "lr": 0.0001,
      "value_lr": 0.003,
      "adam_beta1": 0.9,
      "adam_beta2": 0.95,
      "adam_eps": 1e-05,
      "clip_grad": 1.0,
      "critic_warmup_steps": 0
    },
    "fsdp_config": {
      "forward_prefetch": false,
      "limit_all_gathers": false,
      "backward_prefetch": null,
      "use_orig_params": false,
      "use_liger_kernel": false
    }
  },
  "reward": {
    "use_reward_model": false
  },
  "critic": {
    "use_critic_model": false
  },
  "ray": {
    "local_mode": false,
    "init_kwargs": {
      "num_cpus": 16,
      "num_gpus": 2
    }
  }
}
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
cfg.ray.local_mode: False
os.environ.get('RAY_LOCAL_MODE', 'not set'): not set
[INFO 19:33:52 FlexiblePlacementStrategy] 
[INFO 19:33:52 FlexiblePlacementStrategy] Using flexible placement with accelerator IDs: [[0], [1]].
[INFO 19:33:52 FlexiblePlacementStrategy] 
[INFO 19:33:52 FlexiblePlacementStrategy] Using flexible placement with accelerator IDs: [[0], [1]].
[INFO 19:33:52 FlexiblePlacementStrategy] 
[INFO 19:33:52 FlexiblePlacementStrategy] Using flexible placement with accelerator IDs: [[0], [1]].
[INFO 19:33:52 FlexiblePlacementStrategy] Generated 2 placements: [Placement(rank=0, node_id=0, node_rank=0, local_accelerator_id=0, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=0, local_world_size=2, visible_accelerators=['0'], isolate_accelerator=True), Placement(rank=1, node_id=0, node_rank=0, local_accelerator_id=1, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=1, local_world_size=2, visible_accelerators=['1'], isolate_accelerator=True)].
[INFO 19:33:53 FlexiblePlacementStrategy] Generated 2 placements: [Placement(rank=0, node_id=0, node_rank=0, local_accelerator_id=0, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=0, local_world_size=2, visible_accelerators=['0'], isolate_accelerator=True), Placement(rank=1, node_id=0, node_rank=0, local_accelerator_id=1, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=1, local_world_size=2, visible_accelerators=['1'], isolate_accelerator=True)].
[INFO 19:33:53 FlexiblePlacementStrategy] Generated 2 placements: [Placement(rank=0, node_id=0, node_rank=0, local_accelerator_id=0, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=0, local_world_size=2, visible_accelerators=['0'], isolate_accelerator=True), Placement(rank=1, node_id=0, node_rank=0, local_accelerator_id=1, accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=1, local_world_size=2, visible_accelerators=['1'], isolate_accelerator=True)].
[36m(EnvWorker pid=1482205)[0m [INFO 19:34:01 NodePlacementStrategy] 
[36m(EnvWorker pid=1482205)[0m [INFO 19:34:01 NodePlacementStrategy] Using node placement with node IDs: [0].
[36m(EnvWorker pid=1482205)[0m [INFO 19:34:01 NodePlacementStrategy] Generated 1 placements: [Placement(rank=0, node_id=0, node_rank=0, local_accelerator_id='0', accelerator_type=<AcceleratorType.NV_GPU: 'NV_GPU'>, local_rank=0, local_world_size=1, visible_accelerators=['0', '1'], isolate_accelerator=True)].
[36m(EmbodiedFSDPActor pid=1482201)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(EmbodiedFSDPActor pid=1482199)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(EmbodiedFSDPActor pid=1482199)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.36it/s]
[36m(EmbodiedFSDPActor pid=1482201)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.31it/s]
[36m(EmbodiedFSDPActor pid=1482201)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.89it/s]
[36m(EmbodiedFSDPActor pid=1482199)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.84it/s]
[36m(EmbodiedFSDPActor pid=1482201)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  3.15it/s]
[36m(EmbodiedFSDPActor pid=1482199)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  3.07it/s]
[36m(EmbodiedFSDPActor pid=1482201)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.34it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.14it/s]
[36m(EmbodiedFSDPActor pid=1482199)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.26it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.08it/s]
[36m(MultiStepRolloutWorker pid=1482204)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.26it/s]
[36m(MultiStepRolloutWorker pid=1482204)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.36it/s]
[36m(MultiStepRolloutWorker pid=1482204)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.91it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  2.74it/s]
[36m(MultiStepRolloutWorker pid=1482204)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.15it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:01<00:00,  3.05it/s]
[36m(MultiStepRolloutWorker pid=1482204)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.33it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.14it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.05it/s]
[36m(EnvWorker pid=1482205)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/sapien/_vulkan_tricks.py:95: UserWarning: Failed to find glvnd ICD file. This is probably due to an incorrect or partial installation of the NVIDIA driver. SAPIEN will attempt to provide an ICD file anyway but it may not work.
[36m(EnvWorker pid=1482205)[0m   warn(
[36m(EnvWorker pid=1482207)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/sapien/_vulkan_tricks.py:95: UserWarning: Failed to find glvnd ICD file. This is probably due to an incorrect or partial installation of the NVIDIA driver. SAPIEN will attempt to provide an ICD file anyway but it may not work.
[36m(EnvWorker pid=1482207)[0m   warn(
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:37,978 - mani_skill  - WARNING - Mimic targets dictionary is missing for controller config for widowx250s_bridgedataset_flat_table. Assuming the first joint is the control joint and the second joint is the mimic joint[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:38,000 - mani_skill  - WARNING - Mimic targets dictionary is missing for controller config for widowx250s_bridgedataset_flat_table. Assuming the first joint is the control joint and the second joint is the mimic joint[0m
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:38,146 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_carrot_generated_modified, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:38,164 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_plate_objaverse_larger, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:38,144 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_carrot_generated_modified, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:38,164 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_plate_objaverse_larger, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482207)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.xyz_configs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.xyz_configs` for environment variables or `env.get_wrapper_attr('xyz_configs')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482207)[0m   logger.warn(
[36m(EnvWorker pid=1482207)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.quat_configs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.quat_configs` for environment variables or `env.get_wrapper_attr('quat_configs')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482207)[0m   logger.warn(
[36m(EnvWorker pid=1482205)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.xyz_configs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.xyz_configs` for environment variables or `env.get_wrapper_attr('xyz_configs')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482205)[0m   logger.warn(
[36m(EnvWorker pid=1482205)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.quat_configs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.quat_configs` for environment variables or `env.get_wrapper_attr('quat_configs')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482205)[0m   logger.warn(
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:40,125 - mani_skill  - WARNING - Mimic targets dictionary is missing for controller config for widowx250s_bridgedataset_flat_table. Assuming the first joint is the control joint and the second joint is the mimic joint[0m
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:40,138 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_carrot_generated_modified, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482207)[0m [33;1m2025-11-05 19:35:40,139 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_plate_objaverse_larger, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:40,174 - mani_skill  - WARNING - Mimic targets dictionary is missing for controller config for widowx250s_bridgedataset_flat_table. Assuming the first joint is the control joint and the second joint is the mimic joint[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:40,185 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_carrot_generated_modified, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EnvWorker pid=1482205)[0m [33;1m2025-11-05 19:35:40,187 - mani_skill  - WARNING - No initial pose set for actor builder of bridge_plate_objaverse_larger, setting to default pose q=[1,0,0,0], p=[0,0,0]. Not setting reasonable initial poses may slow down simulation, see https://github.com/haosulab/ManiSkill/issues/421.[0m
[36m(EmbodiedFSDPActor pid=1482199)[0m layer_class is : LlamaDecoderLayer
[36m(EmbodiedFSDPActor pid=1482201)[0m layer_class is : LlamaDecoderLayer
Global Step:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0/1000 [00:00<?, ?it/s][36m(EmbodiedFSDPActor pid=1482201)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:150: UserWarning: offload_to_cpu=True and rank0_only=False may result in theunsharded parameters being redundantly copied to CPU memory for GPUs sharing the same CPU memory, which risks CPU OOM. We recommend using offload_to_cpu=True with rank0_only=True.
[36m(EmbodiedFSDPActor pid=1482201)[0m   warnings.warn(
[36m(EmbodiedFSDPActor pid=1482199)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:150: UserWarning: offload_to_cpu=True and rank0_only=False may result in theunsharded parameters being redundantly copied to CPU memory for GPUs sharing the same CPU memory, which risks CPU OOM. We recommend using offload_to_cpu=True with rank0_only=True.
[36m(EmbodiedFSDPActor pid=1482199)[0m   warnings.warn(
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(EnvWorker pid=1482207)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.device to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.device` for environment variables or `env.get_wrapper_attr('device')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482207)[0m   logger.warn(
[36m(EnvWorker pid=1482205)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.device to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.device` for environment variables or `env.get_wrapper_attr('device')` that will search the reminding wrappers.[0m
[36m(EnvWorker pid=1482205)[0m   logger.warn(
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.78s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.78s/it]
Global Step:   0%| | 0/1000 [08:01<?, ?it/s, time/rollout=290, time/cal_adv_and_returns=0.0159, time/actor_training=192, time/step=482, env/success_once=0.53125, env/return=0.696875, env/episode_len=80.0, env/reward=0.008710938, env/success_at_end=0.53125, rollout/rewards=0.0082, rollout/advantages_mean=4.84e-9, rollout/advantages_max=4.71, rollout/advantages_min=-1.03, rollout/returns_mean=0.0808, rollout/returns_max=0.996, rollout/returns_min=-0.107, train/actor/approx_kl=inf, train/actor/clip_fraction=0.376, train/actor/clipped_ratio=0.941, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=20.5, train/actor/lr=0.0001, train/actor/policy_loss=0.162, train/actor/ratio=0.972, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00859, train/critic/value_loss=0.188, train/entropy_losGlobal Step:   0%| | 1/1000 [08:01<133:43:12, 481.87s/it, time/rollout=290, time/cal_adv_and_returns=0.0159, time/actor_training=192, time/step=482, env/success_once=0.53125, env/return=0.696875, env/episode_len=80.0, env/reward=0.008710938, env/success_at_end=0.53125, rollout/rewards=0.0082, rollout/advantages_mean=4.84e-9, rollout/advantages_max=4.71, rollout/advantages_min=-1.03, rollout/returns_mean=0.0808, rollout/returns_max=0.996, rollout/returns_min=-0.107, train/actor/approx_kl=inf, train/actor/clip_fraction=0.376, train/actor/clipped_ratio=0.941, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=20.5, train/actor/lr=0.0001, train/actor/policy_loss=0.162, train/actor/ratio=0.972, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00859, train/critic/value_loss=0.188, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.95s/it]
Global Step:   0%| | 1/1000 [15:43<133:43:12, 481.87s/it, time/rollout=278, time/cal_adv_and_returns=0.012, time/actor_training=183, time/step=461, env/success_once=0.625, env/return=0.778125, env/episode_len=80.0, env/reward=0.009726563, env/success_at_end=0.625, rollout/rewards=0.0101, rollout/advantages_mean=2.01e-8, rollout/advantages_max=4.43, rollout/advantages_min=-4.63, rollout/returns_mean=0.175, rollout/returns_max=1.13, rollout/returns_min=-0.717, train/actor/approx_kl=inf, train/actor/clip_fraction=0.27, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0823, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0414, train/critic/value_loss=0.0182, train/entroGlobal Step:   0%| | 2/1000 [15:43<130:14:12, 469.79s/it, time/rollout=278, time/cal_adv_and_returns=0.012, time/actor_training=183, time/step=461, env/success_once=0.625, env/return=0.778125, env/episode_len=80.0, env/reward=0.009726563, env/success_at_end=0.625, rollout/rewards=0.0101, rollout/advantages_mean=2.01e-8, rollout/advantages_max=4.43, rollout/advantages_min=-4.63, rollout/returns_mean=0.175, rollout/returns_max=1.13, rollout/returns_min=-0.717, train/actor/approx_kl=inf, train/actor/clip_fraction=0.27, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0823, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0414, train/critic/value_loss=0.0182, train/entro[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.64s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.64s/it]
Global Step:   0%| | 2/1000 [23:38<130:14:12, 469.79s/it, time/rollout=279, time/cal_adv_and_returns=0.0206, time/actor_training=196, time/step=475, env/success_once=0.59375, env/return=0.7593749, env/episode_len=80.0, env/reward=0.009492188, env/success_at_end=0.59375, rollout/rewards=0.0105, rollout/advantages_mean=4.02e-8, rollout/advantages_max=5.37, rollout/advantages_min=-3.39, rollout/returns_mean=0.244, rollout/returns_max=1.15, rollout/returns_min=-0.0585, train/actor/approx_kl=inf, train/actor/clip_fraction=0.296, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0853, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.048, train/critic/value_loss=0.0131, trainGlobal Step:   0%| | 3/1000 [23:38<130:44:28, 472.08s/it, time/rollout=279, time/cal_adv_and_returns=0.0206, time/actor_training=196, time/step=475, env/success_once=0.59375, env/return=0.7593749, env/episode_len=80.0, env/reward=0.009492188, env/success_at_end=0.59375, rollout/rewards=0.0105, rollout/advantages_mean=4.02e-8, rollout/advantages_max=5.37, rollout/advantages_min=-3.39, rollout/returns_mean=0.244, rollout/returns_max=1.15, rollout/returns_min=-0.0585, train/actor/approx_kl=inf, train/actor/clip_fraction=0.296, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0853, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.048, train/critic/value_loss=0.0131, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]
Global Step:   0%| | 3/1000 [31:16<130:44:28, 472.08s/it, time/rollout=276, time/cal_adv_and_returns=0.0136, time/actor_training=183, time/step=458, env/success_once=0.65625, env/return=0.8312501, env/episode_len=80.0, env/reward=0.010390625, env/success_at_end=0.65625, rollout/rewards=0.0124, rollout/advantages_mean=-1.4e-8, rollout/advantages_max=4.68, rollout/advantages_min=-4.31, rollout/returns_mean=0.374, rollout/returns_max=1.34, rollout/returns_min=-0.15, train/actor/approx_kl=inf, train/actor/clip_fraction=0.268, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0726, train/actor/ratio=0.998, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0328, train/critic/value_loss=0.0184, train/Global Step:   0%| | 4/1000 [31:16<129:06:03, 466.63s/it, time/rollout=276, time/cal_adv_and_returns=0.0136, time/actor_training=183, time/step=458, env/success_once=0.65625, env/return=0.8312501, env/episode_len=80.0, env/reward=0.010390625, env/success_at_end=0.65625, rollout/rewards=0.0124, rollout/advantages_mean=-1.4e-8, rollout/advantages_max=4.68, rollout/advantages_min=-4.31, rollout/returns_mean=0.374, rollout/returns_max=1.34, rollout/returns_min=-0.15, train/actor/approx_kl=inf, train/actor/clip_fraction=0.268, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0726, train/actor/ratio=0.998, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0328, train/critic/value_loss=0.0184, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.46s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.46s/it]
Global Step:   0%| | 4/1000 [39:04<129:06:03, 466.63s/it, time/rollout=285, time/cal_adv_and_returns=0.0145, time/actor_training=183, time/step=469, env/success_once=0.6875, env/return=0.78125006, env/episode_len=80.0, env/reward=0.009765625, env/success_at_end=0.625, rollout/rewards=0.0124, rollout/advantages_mean=7.45e-10, rollout/advantages_max=5.3, rollout/advantages_min=-7.39, rollout/returns_mean=0.412, rollout/returns_max=1.57, rollout/returns_min=-0.83, train/actor/approx_kl=inf, train/actor/clip_fraction=0.245, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0852, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0238, train/critic/value_loss=0.0165, train/entroGlobal Step:   0%| | 5/1000 [39:04<129:09:36, 467.31s/it, time/rollout=285, time/cal_adv_and_returns=0.0145, time/actor_training=183, time/step=469, env/success_once=0.6875, env/return=0.78125006, env/episode_len=80.0, env/reward=0.009765625, env/success_at_end=0.625, rollout/rewards=0.0124, rollout/advantages_mean=7.45e-10, rollout/advantages_max=5.3, rollout/advantages_min=-7.39, rollout/returns_mean=0.412, rollout/returns_max=1.57, rollout/returns_min=-0.83, train/actor/approx_kl=inf, train/actor/clip_fraction=0.245, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0852, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0238, train/critic/value_loss=0.0165, train/entro[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.06s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.06s/it]
Global Step:   0%| | 5/1000 [47:00<129:09:36, 467.31s/it, time/rollout=293, time/cal_adv_and_returns=0.0738, time/actor_training=182, time/step=476, env/success_once=0.5625, env/return=0.725, env/episode_len=80.0, env/reward=0.0090625, env/success_at_end=0.5625, rollout/rewards=0.0132, rollout/advantages_mean=-5.22e-9, rollout/advantages_max=7.33, rollout/advantages_min=-4.39, rollout/returns_mean=0.482, rollout/returns_max=1.61, rollout/returns_min=-0.123, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0672, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0113, train/critic/value_loss=0.0127, train/entropyGlobal Step:   1%| | 6/1000 [47:00<129:48:56, 470.16s/it, time/rollout=293, time/cal_adv_and_returns=0.0738, time/actor_training=182, time/step=476, env/success_once=0.5625, env/return=0.725, env/episode_len=80.0, env/reward=0.0090625, env/success_at_end=0.5625, rollout/rewards=0.0132, rollout/advantages_mean=-5.22e-9, rollout/advantages_max=7.33, rollout/advantages_min=-4.39, rollout/returns_mean=0.482, rollout/returns_max=1.61, rollout/returns_min=-0.123, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0672, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0113, train/critic/value_loss=0.0127, train/entropy[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.48s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.48s/it]
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [19:40:31] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [19:40:31] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [19:48:20] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [19:48:20] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [19:56:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [19:56:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:03:54] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:03:54] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:11:42] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:11:42] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:19:39] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:19:39] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:27:21] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:27:20] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         Global Step:   1%| | 6/1000 [55:49<129:48:56, 470.16s/it, time/rollout=279, time/cal_adv_and_returns=0.0134, time/actor_training=250, time/step=529, env/success_once=0.65625, env/return=0.7375, env/episode_len=80.0, env/reward=0.0092187505, env/success_at_end=0.5625, rollout/rewards=0.0136, rollout/advantages_mean=-9.5e-9, rollout/advantages_max=5.14, rollout/advantages_min=-6.28, rollout/returns_mean=0.543, rollout/returns_max=1.55, rollout/returns_min=-0.812, train/actor/approx_kl=inf, train/actor/clip_fraction=0.226, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=18, train/actor/lr=0.0001, train/actor/policy_loss=0.0686, train/actor/ratio=0.974, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00547, train/critic/value_loss=0.0166, train/enGlobal Step:   1%| | 7/1000 [55:49<135:01:35, 489.52s/it, time/rollout=279, time/cal_adv_and_returns=0.0134, time/actor_training=250, time/step=529, env/success_once=0.65625, env/return=0.7375, env/episode_len=80.0, env/reward=0.0092187505, env/success_at_end=0.5625, rollout/rewards=0.0136, rollout/advantages_mean=-9.5e-9, rollout/advantages_max=5.14, rollout/advantages_min=-6.28, rollout/returns_mean=0.543, rollout/returns_max=1.55, rollout/returns_min=-0.812, train/actor/approx_kl=inf, train/actor/clip_fraction=0.226, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=18, train/actor/lr=0.0001, train/actor/policy_loss=0.0686, train/actor/ratio=0.974, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00547, train/critic/value_loss=0.0166, train/en[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.66s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.66s/it]
Global Step:   1%| | 7/1000 [1:04:40<135:01:35, 489.52s/it, time/rollout=282, time/cal_adv_and_returns=0.0141, time/actor_training=249, time/step=530, env/success_once=0.59375, env/return=0.73125005, env/episode_len=80.0, env/reward=0.009140625, env/success_at_end=0.5625, rollout/rewards=0.014, rollout/advantages_mean=1.79e-8, rollout/advantages_max=6.37, rollout/advantages_min=-6.81, rollout/returns_mean=0.548, rollout/returns_max=1.48, rollout/returns_min=-0.403, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.96, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17, train/actor/lr=0.0001, train/actor/policy_loss=0.0791, train/actor/ratio=0.979, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00742, train/critic/value_loss=0.0128, train/Global Step:   1%| | 8/1000 [1:04:40<138:28:23, 502.52s/it, time/rollout=282, time/cal_adv_and_returns=0.0141, time/actor_training=249, time/step=530, env/success_once=0.59375, env/return=0.73125005, env/episode_len=80.0, env/reward=0.009140625, env/success_at_end=0.5625, rollout/rewards=0.014, rollout/advantages_mean=1.79e-8, rollout/advantages_max=6.37, rollout/advantages_min=-6.81, rollout/returns_mean=0.548, rollout/returns_max=1.48, rollout/returns_min=-0.403, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.96, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17, train/actor/lr=0.0001, train/actor/policy_loss=0.0791, train/actor/ratio=0.979, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00742, train/critic/value_loss=0.0128, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.58s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.58s/it]
Global Step:   1%| | 8/1000 [1:13:38<138:28:23, 502.52s/it, time/rollout=286, time/cal_adv_and_returns=0.0166, time/actor_training=252, time/step=539, env/success_once=0.625, env/return=0.6812501, env/episode_len=80.0, env/reward=0.008515624, env/success_at_end=0.5625, rollout/rewards=0.0133, rollout/advantages_mean=6.71e-9, rollout/advantages_max=5.38, rollout/advantages_min=-6.61, rollout/returns_mean=0.553, rollout/returns_max=1.45, rollout/returns_min=-0.4, train/actor/approx_kl=inf, train/actor/clip_fraction=0.247, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0629, train/actor/ratio=0.99, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00703, train/critic/value_loss=0.0121, train/eGlobal Step:   1%| | 9/1000 [1:13:38<141:25:49, 513.77s/it, time/rollout=286, time/cal_adv_and_returns=0.0166, time/actor_training=252, time/step=539, env/success_once=0.625, env/return=0.6812501, env/episode_len=80.0, env/reward=0.008515624, env/success_at_end=0.5625, rollout/rewards=0.0133, rollout/advantages_mean=6.71e-9, rollout/advantages_max=5.38, rollout/advantages_min=-6.61, rollout/returns_mean=0.553, rollout/returns_max=1.45, rollout/returns_min=-0.4, train/actor/approx_kl=inf, train/actor/clip_fraction=0.247, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0629, train/actor/ratio=0.99, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00703, train/critic/value_loss=0.0121, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.62s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.62s/it]
Global Step:   1%| | 9/1000 [1:22:36<141:25:49, 513.77s/it, time/rollout=285, time/cal_adv_and_returns=0.015, time/actor_training=252, time/step=537, env/success_once=0.65625, env/return=0.77812505, env/episode_len=80.0, env/reward=0.0097265635, env/success_at_end=0.59375, rollout/rewards=0.0143, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=5.91, rollout/advantages_min=-5.72, rollout/returns_mean=0.566, rollout/returns_max=1.44, rollout/returns_min=-0.707, train/actor/approx_kl=inf, train/actor/clip_fraction=0.217, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0572, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00742, train/critic/value_loss=0.0127,Global Step:   1%| | 10/1000 [1:22:36<143:17:25, 521.06s/it, time/rollout=285, time/cal_adv_and_returns=0.015, time/actor_training=252, time/step=537, env/success_once=0.65625, env/return=0.77812505, env/episode_len=80.0, env/reward=0.0097265635, env/success_at_end=0.59375, rollout/rewards=0.0143, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=5.91, rollout/advantages_min=-5.72, rollout/returns_mean=0.566, rollout/returns_max=1.44, rollout/returns_min=-0.707, train/actor/approx_kl=inf, train/actor/clip_fraction=0.217, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0572, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00742, train/critic/value_loss=0.0127[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.98s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.98s/it]
Global Step:   1%| | 10/1000 [1:30:13<143:17:25, 521.06s/it, time/rollout=279, time/cal_adv_and_returns=0.0141, time/actor_training=179, time/step=458, env/success_once=0.65625, env/return=0.7312501, env/episode_len=80.0, env/reward=0.009140625, env/success_at_end=0.5625, rollout/rewards=0.0125, rollout/advantages_mean=1.02e-8, rollout/advantages_max=5.59, rollout/advantages_min=-7.73, rollout/returns_mean=0.484, rollout/returns_max=1.46, rollout/returns_min=-0.844, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=24.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0847, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0138, trGlobal Step:   1%| | 11/1000 [1:30:13<137:48:43, 501.64s/it, time/rollout=279, time/cal_adv_and_returns=0.0141, time/actor_training=179, time/step=458, env/success_once=0.65625, env/return=0.7312501, env/episode_len=80.0, env/reward=0.009140625, env/success_at_end=0.5625, rollout/rewards=0.0125, rollout/advantages_mean=1.02e-8, rollout/advantages_max=5.59, rollout/advantages_min=-7.73, rollout/returns_mean=0.484, rollout/returns_max=1.46, rollout/returns_min=-0.844, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=24.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0847, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0138, tr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.50s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.50s/it]
Global Step:   1%| | 11/1000 [1:37:52<137:48:43, 501.64s/it, time/rollout=277, time/cal_adv_and_returns=0.0132, time/actor_training=182, time/step=459, env/success_once=0.71875, env/return=0.803125, env/episode_len=80.0, env/reward=0.010039063, env/success_at_end=0.625, rollout/rewards=0.0128, rollout/advantages_mean=3.73e-9, rollout/advantages_max=5.82, rollout/advantages_min=-5.64, rollout/returns_mean=0.434, rollout/returns_max=1.3, rollout/returns_min=-0.875, train/actor/approx_kl=inf, train/actor/clip_fraction=0.243, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=24.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0827, train/actor/ratio=0.984, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0113, train/critic/value_loss=0.0179, trainGlobal Step:   1%| | 12/1000 [1:37:52<134:06:34, 488.66s/it, time/rollout=277, time/cal_adv_and_returns=0.0132, time/actor_training=182, time/step=459, env/success_once=0.71875, env/return=0.803125, env/episode_len=80.0, env/reward=0.010039063, env/success_at_end=0.625, rollout/rewards=0.0128, rollout/advantages_mean=3.73e-9, rollout/advantages_max=5.82, rollout/advantages_min=-5.64, rollout/returns_mean=0.434, rollout/returns_max=1.3, rollout/returns_min=-0.875, train/actor/approx_kl=inf, train/actor/clip_fraction=0.243, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=24.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0827, train/actor/ratio=0.984, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0113, train/critic/value_loss=0.0179, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.43s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.43s/it]
Global Step:   1%| | 12/1000 [1:45:26<134:06:34, 488.66s/it, time/rollout=278, time/cal_adv_and_returns=0.0132, time/actor_training=175, time/step=453, env/success_once=0.65625, env/return=0.83125013, env/episode_len=80.0, env/reward=0.010390625, env/success_at_end=0.65625, rollout/rewards=0.013, rollout/advantages_mean=8.2e-9, rollout/advantages_max=6.81, rollout/advantages_min=-6.17, rollout/returns_mean=0.44, rollout/returns_max=1.2, rollout/returns_min=-0.232, train/actor/approx_kl=inf, train/actor/clip_fraction=0.238, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0602, train/actor/ratio=0.999, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0115, traGlobal Step:   1%| | 13/1000 [1:45:26<131:03:14, 478.01s/it, time/rollout=278, time/cal_adv_and_returns=0.0132, time/actor_training=175, time/step=453, env/success_once=0.65625, env/return=0.83125013, env/episode_len=80.0, env/reward=0.010390625, env/success_at_end=0.65625, rollout/rewards=0.013, rollout/advantages_mean=8.2e-9, rollout/advantages_max=6.81, rollout/advantages_min=-6.17, rollout/returns_mean=0.44, rollout/returns_max=1.2, rollout/returns_min=-0.232, train/actor/approx_kl=inf, train/actor/clip_fraction=0.238, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0602, train/actor/ratio=0.999, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0115, tra[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.29s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.29s/it]

[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:36:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:36:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:45:07] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:45:07] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [20:54:05] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [20:54:05] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:02:55] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:02:55] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:10:32] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:10:32] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:18:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:18:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:25:44] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:25:44] WARNING  | >> Only support splitting     data_iter_utils.py:159Global Step:   1%| | 13/1000 [1:53:01<131:03:14, 478.01s/it, time/rollout=277, time/cal_adv_and_returns=0.0385, time/actor_training=179, time/step=456, env/success_once=0.5625, env/return=0.7250001, env/episode_len=80.0, env/reward=0.009062501, env/success_at_end=0.5625, rollout/rewards=0.0125, rollout/advantages_mean=-8.94e-9, rollout/advantages_max=7.7, rollout/advantages_min=-6.32, rollout/returns_mean=0.458, rollout/returns_max=1.32, rollout/returns_min=0.0174, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0606, train/actor/ratio=0.979, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0103, tGlobal Step:   1%| | 14/1000 [1:53:01<129:04:23, 471.26s/it, time/rollout=277, time/cal_adv_and_returns=0.0385, time/actor_training=179, time/step=456, env/success_once=0.5625, env/return=0.7250001, env/episode_len=80.0, env/reward=0.009062501, env/success_at_end=0.5625, rollout/rewards=0.0125, rollout/advantages_mean=-8.94e-9, rollout/advantages_max=7.7, rollout/advantages_min=-6.32, rollout/returns_mean=0.458, rollout/returns_max=1.32, rollout/returns_min=0.0174, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0606, train/actor/ratio=0.979, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0103, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.31s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.31s/it]
Global Step:   1%| | 14/1000 [2:00:39<129:04:23, 471.26s/it, time/rollout=277, time/cal_adv_and_returns=0.0131, time/actor_training=181, time/step=458, env/success_once=0.71875, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367188, env/success_at_end=0.71875, rollout/rewards=0.0144, rollout/advantages_mean=6.71e-9, rollout/advantages_max=7.28, rollout/advantages_min=-6.44, rollout/returns_mean=0.463, rollout/returns_max=1.28, rollout/returns_min=-0.0966, train/actor/approx_kl=inf, train/actor/clip_fraction=0.234, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0619, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.00969, Global Step:   2%| | 15/1000 [2:00:39<127:49:50, 467.20s/it, time/rollout=277, time/cal_adv_and_returns=0.0131, time/actor_training=181, time/step=458, env/success_once=0.71875, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367188, env/success_at_end=0.71875, rollout/rewards=0.0144, rollout/advantages_mean=6.71e-9, rollout/advantages_max=7.28, rollout/advantages_min=-6.44, rollout/returns_mean=0.463, rollout/returns_max=1.28, rollout/returns_min=-0.0966, train/actor/approx_kl=inf, train/actor/clip_fraction=0.234, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0619, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.00969, [36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it]
Global Step:   2%| | 15/1000 [2:08:21<127:49:50, 467.20s/it, time/rollout=278, time/cal_adv_and_returns=0.0139, time/actor_training=184, time/step=462, env/success_once=0.75, env/return=0.92187506, env/episode_len=80.0, env/reward=0.011523439, env/success_at_end=0.75, rollout/rewards=0.0145, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=6.56, rollout/advantages_min=-3.81, rollout/returns_mean=0.476, rollout/returns_max=1.24, rollout/returns_min=-0.137, train/actor/approx_kl=inf, train/actor/clip_fraction=0.254, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.8, train/actor/lr=0.0001, train/actor/policy_loss=0.064, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00586, train/critic/value_loss=0.0101, trainGlobal Step:   2%| | 16/1000 [2:08:21<127:17:41, 465.71s/it, time/rollout=278, time/cal_adv_and_returns=0.0139, time/actor_training=184, time/step=462, env/success_once=0.75, env/return=0.92187506, env/episode_len=80.0, env/reward=0.011523439, env/success_at_end=0.75, rollout/rewards=0.0145, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=6.56, rollout/advantages_min=-3.81, rollout/returns_mean=0.476, rollout/returns_max=1.24, rollout/returns_min=-0.137, train/actor/approx_kl=inf, train/actor/clip_fraction=0.254, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.8, train/actor/lr=0.0001, train/actor/policy_loss=0.064, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00586, train/critic/value_loss=0.0101, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.02s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.02s/it]
Global Step:   2%| | 16/1000 [2:15:55<127:17:41, 465.71s/it, time/rollout=275, time/cal_adv_and_returns=0.0134, time/actor_training=179, time/step=454, env/success_once=0.71875, env/return=0.8875001, env/episode_len=80.0, env/reward=0.01109375, env/success_at_end=0.71875, rollout/rewards=0.0139, rollout/advantages_mean=1.49e-9, rollout/advantages_max=6.96, rollout/advantages_min=-5.98, rollout/returns_mean=0.529, rollout/returns_max=1.56, rollout/returns_min=-0.0303, train/actor/approx_kl=inf, train/actor/clip_fraction=0.196, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0597, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0107, traiGlobal Step:   2%| | 17/1000 [2:15:55<126:12:03, 462.18s/it, time/rollout=275, time/cal_adv_and_returns=0.0134, time/actor_training=179, time/step=454, env/success_once=0.71875, env/return=0.8875001, env/episode_len=80.0, env/reward=0.01109375, env/success_at_end=0.71875, rollout/rewards=0.0139, rollout/advantages_mean=1.49e-9, rollout/advantages_max=6.96, rollout/advantages_min=-5.98, rollout/returns_mean=0.529, rollout/returns_max=1.56, rollout/returns_min=-0.0303, train/actor/approx_kl=inf, train/actor/clip_fraction=0.196, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0597, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0107, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.14s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.14s/it]
Global Step:   2%| | 17/1000 [2:23:38<126:12:03, 462.18s/it, time/rollout=281, time/cal_adv_and_returns=0.0139, time/actor_training=182, time/step=463, env/success_once=0.78125, env/return=0.96562505, env/episode_len=80.0, env/reward=0.012070313, env/success_at_end=0.78125, rollout/rewards=0.0161, rollout/advantages_mean=2.24e-9, rollout/advantages_max=6.74, rollout/advantages_min=-6.26, rollout/returns_mean=0.579, rollout/returns_max=1.27, rollout/returns_min=-0.0789, train/actor/approx_kl=inf, train/actor/clip_fraction=0.216, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.1, train/actor/lr=0.0001, train/actor/policy_loss=0.088, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0125, train/critic/value_loss=0.0107, tGlobal Step:   2%| | 18/1000 [2:23:38<126:08:16, 462.42s/it, time/rollout=281, time/cal_adv_and_returns=0.0139, time/actor_training=182, time/step=463, env/success_once=0.78125, env/return=0.96562505, env/episode_len=80.0, env/reward=0.012070313, env/success_at_end=0.78125, rollout/rewards=0.0161, rollout/advantages_mean=2.24e-9, rollout/advantages_max=6.74, rollout/advantages_min=-6.26, rollout/returns_mean=0.579, rollout/returns_max=1.27, rollout/returns_min=-0.0789, train/actor/approx_kl=inf, train/actor/clip_fraction=0.216, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.1, train/actor/lr=0.0001, train/actor/policy_loss=0.088, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0125, train/critic/value_loss=0.0107, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.35s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.35s/it]
Global Step:   2%| | 18/1000 [2:31:21<126:08:16, 462.42s/it, time/rollout=280, time/cal_adv_and_returns=0.0145, time/actor_training=182, time/step=462, env/success_once=0.71875, env/return=0.8531251, env/episode_len=80.0, env/reward=0.010664063, env/success_at_end=0.6875, rollout/rewards=0.0149, rollout/advantages_mean=-2.31e-8, rollout/advantages_max=8.54, rollout/advantages_min=-4.93, rollout/returns_mean=0.608, rollout/returns_max=1.77, rollout/returns_min=-0.548, train/actor/approx_kl=inf, train/actor/clip_fraction=0.232, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0619, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.014, tGlobal Step:   2%| | 19/1000 [2:31:21<126:00:02, 462.39s/it, time/rollout=280, time/cal_adv_and_returns=0.0145, time/actor_training=182, time/step=462, env/success_once=0.71875, env/return=0.8531251, env/episode_len=80.0, env/reward=0.010664063, env/success_at_end=0.6875, rollout/rewards=0.0149, rollout/advantages_mean=-2.31e-8, rollout/advantages_max=8.54, rollout/advantages_min=-4.93, rollout/returns_mean=0.608, rollout/returns_max=1.77, rollout/returns_min=-0.548, train/actor/approx_kl=inf, train/actor/clip_fraction=0.232, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0619, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.014, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.46s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.46s/it]
Global Step:   2%| | 19/1000 [2:39:00<126:00:02, 462.39s/it, time/rollout=276, time/cal_adv_and_returns=0.0146, time/actor_training=183, time/step=459, env/success_once=0.75, env/return=0.8781251, env/episode_len=80.0, env/reward=0.010976563, env/success_at_end=0.6875, rollout/rewards=0.0151, rollout/advantages_mean=-1.19e-8, rollout/advantages_max=8.13, rollout/advantages_min=-8.05, rollout/returns_mean=0.572, rollout/returns_max=1.48, rollout/returns_min=-0.812, train/actor/approx_kl=inf, train/actor/clip_fraction=0.209, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0558, train/actor/ratio=0.978, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0119, train/entGlobal Step:   2%| | 20/1000 [2:39:00<125:35:00, 461.33s/it, time/rollout=276, time/cal_adv_and_returns=0.0146, time/actor_training=183, time/step=459, env/success_once=0.75, env/return=0.8781251, env/episode_len=80.0, env/reward=0.010976563, env/success_at_end=0.6875, rollout/rewards=0.0151, rollout/advantages_mean=-1.19e-8, rollout/advantages_max=8.13, rollout/advantages_min=-8.05, rollout/returns_mean=0.572, rollout/returns_max=1.48, rollout/returns_min=-0.812, train/actor/approx_kl=inf, train/actor/clip_fraction=0.209, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0558, train/actor/ratio=0.978, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0119, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.87s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.87s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:33:20] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:33:20] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:40:58] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:40:58] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:48:38] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:48:38] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [21:56:18] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [21:56:18] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:04:00] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:04:00] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:11:38] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:11:38] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:19:17] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         Global Step:   2%| | 20/1000 [2:46:47<125:35:00, 461.33s/it, time/rollout=277, time/cal_adv_and_returns=0.014, time/actor_training=191, time/step=467, env/success_once=0.84375, env/return=1.003125, env/episode_len=80.0, env/reward=0.012539063, env/success_at_end=0.8125, rollout/rewards=0.017, rollout/advantages_mean=2.61e-9, rollout/advantages_max=6.85, rollout/advantages_min=-4.94, rollout/returns_mean=0.624, rollout/returns_max=1.67, rollout/returns_min=-0.69, train/actor/approx_kl=inf, train/actor/clip_fraction=0.212, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0694, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0129, train/critic/value_loss=0.0143, train/entrGlobal Step:   2%| | 21/1000 [2:46:47<125:56:35, 463.12s/it, time/rollout=277, time/cal_adv_and_returns=0.014, time/actor_training=191, time/step=467, env/success_once=0.84375, env/return=1.003125, env/episode_len=80.0, env/reward=0.012539063, env/success_at_end=0.8125, rollout/rewards=0.017, rollout/advantages_mean=2.61e-9, rollout/advantages_max=6.85, rollout/advantages_min=-4.94, rollout/returns_mean=0.624, rollout/returns_max=1.67, rollout/returns_min=-0.69, train/actor/approx_kl=inf, train/actor/clip_fraction=0.212, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0694, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0129, train/critic/value_loss=0.0143, train/entr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.45s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.45s/it]
Global Step:   2%| | 21/1000 [2:54:47<125:56:35, 463.12s/it, time/rollout=281, time/cal_adv_and_returns=0.013, time/actor_training=199, time/step=480, env/success_once=0.65625, env/return=0.771875, env/episode_len=80.0, env/reward=0.009648438, env/success_at_end=0.59375, rollout/rewards=0.0155, rollout/advantages_mean=1.79e-8, rollout/advantages_max=5.82, rollout/advantages_min=-6.77, rollout/returns_mean=0.641, rollout/returns_max=1.5, rollout/returns_min=-0.361, train/actor/approx_kl=inf, train/actor/clip_fraction=0.213, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0608, train/actor/ratio=0.984, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00273, train/critic/value_loss=0.0128, traGlobal Step:   2%| | 22/1000 [2:54:47<127:13:43, 468.33s/it, time/rollout=281, time/cal_adv_and_returns=0.013, time/actor_training=199, time/step=480, env/success_once=0.65625, env/return=0.771875, env/episode_len=80.0, env/reward=0.009648438, env/success_at_end=0.59375, rollout/rewards=0.0155, rollout/advantages_mean=1.79e-8, rollout/advantages_max=5.82, rollout/advantages_min=-6.77, rollout/returns_mean=0.641, rollout/returns_max=1.5, rollout/returns_min=-0.361, train/actor/approx_kl=inf, train/actor/clip_fraction=0.213, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0608, train/actor/ratio=0.984, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00273, train/critic/value_loss=0.0128, tra[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.10s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.10s/it]
Global Step:   2%| | 22/1000 [3:02:26<127:13:43, 468.33s/it, time/rollout=275, time/cal_adv_and_returns=0.013, time/actor_training=184, time/step=459, env/success_once=0.625, env/return=0.771875, env/episode_len=80.0, env/reward=0.009648438, env/success_at_end=0.59375, rollout/rewards=0.0142, rollout/advantages_mean=-1.49e-9, rollout/advantages_max=5.95, rollout/advantages_min=-7.48, rollout/returns_mean=0.532, rollout/returns_max=1.33, rollout/returns_min=-0.607, train/actor/approx_kl=inf, train/actor/clip_fraction=0.23, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0709, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0154, trainGlobal Step:   2%| | 23/1000 [3:02:26<126:19:17, 465.46s/it, time/rollout=275, time/cal_adv_and_returns=0.013, time/actor_training=184, time/step=459, env/success_once=0.625, env/return=0.771875, env/episode_len=80.0, env/reward=0.009648438, env/success_at_end=0.59375, rollout/rewards=0.0142, rollout/advantages_mean=-1.49e-9, rollout/advantages_max=5.95, rollout/advantages_min=-7.48, rollout/returns_mean=0.532, rollout/returns_max=1.33, rollout/returns_min=-0.607, train/actor/approx_kl=inf, train/actor/clip_fraction=0.23, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0709, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0154, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.32s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.32s/it]
Global Step:   2%| | 23/1000 [3:10:10<126:19:17, 465.46s/it, time/rollout=281, time/cal_adv_and_returns=0.0119, time/actor_training=183, time/step=464, env/success_once=0.625, env/return=0.74375, env/episode_len=80.0, env/reward=0.009296875, env/success_at_end=0.5625, rollout/rewards=0.0137, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=7, rollout/advantages_min=-8.5, rollout/returns_mean=0.531, rollout/returns_max=1.29, rollout/returns_min=-0.738, train/actor/approx_kl=inf, train/actor/clip_fraction=0.212, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0405, train/actor/ratio=0.988, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.00962, train/entropyGlobal Step:   2%| | 24/1000 [3:10:10<126:02:43, 464.92s/it, time/rollout=281, time/cal_adv_and_returns=0.0119, time/actor_training=183, time/step=464, env/success_once=0.625, env/return=0.74375, env/episode_len=80.0, env/reward=0.009296875, env/success_at_end=0.5625, rollout/rewards=0.0137, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=7, rollout/advantages_min=-8.5, rollout/returns_mean=0.531, rollout/returns_max=1.29, rollout/returns_min=-0.738, train/actor/approx_kl=inf, train/actor/clip_fraction=0.212, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0405, train/actor/ratio=0.988, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.00962, train/entropy[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.69s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.69s/it]
Global Step:   2%| | 24/1000 [3:17:49<126:02:43, 464.92s/it, time/rollout=274, time/cal_adv_and_returns=0.013, time/actor_training=185, time/step=459, env/success_once=0.71875, env/return=0.875, env/episode_len=80.0, env/reward=0.010937501, env/success_at_end=0.6875, rollout/rewards=0.0147, rollout/advantages_mean=-9.31e-9, rollout/advantages_max=6.79, rollout/advantages_min=-7.34, rollout/returns_mean=0.527, rollout/returns_max=1.35, rollout/returns_min=-0.457, train/actor/approx_kl=inf, train/actor/clip_fraction=0.27, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0662, train/actor/ratio=0.992, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0104, train/Global Step:   2%| | 25/1000 [3:17:49<125:25:50, 463.13s/it, time/rollout=274, time/cal_adv_and_returns=0.013, time/actor_training=185, time/step=459, env/success_once=0.71875, env/return=0.875, env/episode_len=80.0, env/reward=0.010937501, env/success_at_end=0.6875, rollout/rewards=0.0147, rollout/advantages_mean=-9.31e-9, rollout/advantages_max=6.79, rollout/advantages_min=-7.34, rollout/returns_mean=0.527, rollout/returns_max=1.35, rollout/returns_min=-0.457, train/actor/approx_kl=inf, train/actor/clip_fraction=0.27, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0662, train/actor/ratio=0.992, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0104, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.76s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.76s/it]
Global Step:   2%| | 25/1000 [3:25:26<125:25:50, 463.13s/it, time/rollout=273, time/cal_adv_and_returns=0.0136, time/actor_training=184, time/step=457, env/success_once=0.875, env/return=0.98749995, env/episode_len=80.0, env/reward=0.012343751, env/success_at_end=0.8125, rollout/rewards=0.0149, rollout/advantages_mean=5.22e-9, rollout/advantages_max=6.27, rollout/advantages_min=-5.98, rollout/returns_mean=0.491, rollout/returns_max=1.24, rollout/returns_min=-0.869, train/actor/approx_kl=inf, train/actor/clip_fraction=0.26, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0439, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.0119, traiGlobal Step:   3%| | 26/1000 [3:25:26<124:49:13, 461.35s/it, time/rollout=273, time/cal_adv_and_returns=0.0136, time/actor_training=184, time/step=457, env/success_once=0.875, env/return=0.98749995, env/episode_len=80.0, env/reward=0.012343751, env/success_at_end=0.8125, rollout/rewards=0.0149, rollout/advantages_mean=5.22e-9, rollout/advantages_max=6.27, rollout/advantages_min=-5.98, rollout/returns_mean=0.491, rollout/returns_max=1.24, rollout/returns_min=-0.869, train/actor/approx_kl=inf, train/actor/clip_fraction=0.26, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0439, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.0119, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.41s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.41s/it]
Global Step:   3%| | 26/1000 [3:33:04<124:49:13, 461.35s/it, time/rollout=277, time/cal_adv_and_returns=0.0548, time/actor_training=181, time/step=458, env/success_once=0.75, env/return=0.846875, env/episode_len=80.0, env/reward=0.010585938, env/success_at_end=0.65625, rollout/rewards=0.0144, rollout/advantages_mean=-7.82e-9, rollout/advantages_max=5.85, rollout/advantages_min=-5.83, rollout/returns_mean=0.515, rollout/returns_max=1.51, rollout/returns_min=-0.694, train/actor/approx_kl=inf, train/actor/clip_fraction=0.232, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0729, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0161, train/eGlobal Step:   3%| | 27/1000 [3:33:04<124:25:07, 460.34s/it, time/rollout=277, time/cal_adv_and_returns=0.0548, time/actor_training=181, time/step=458, env/success_once=0.75, env/return=0.846875, env/episode_len=80.0, env/reward=0.010585938, env/success_at_end=0.65625, rollout/rewards=0.0144, rollout/advantages_mean=-7.82e-9, rollout/advantages_max=5.85, rollout/advantages_min=-5.83, rollout/returns_mean=0.515, rollout/returns_max=1.51, rollout/returns_min=-0.694, train/actor/approx_kl=inf, train/actor/clip_fraction=0.232, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0729, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0161, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.48s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.48s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:19:17] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:27:09] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:27:09] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:35:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:35:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:42:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:42:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:50:25] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:50:25] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [22:58:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [22:58:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:05:44] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:05:44] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:13:18] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                Global Step:   3%| | 27/1000 [3:40:42<124:25:07, 460.34s/it, time/rollout=273, time/cal_adv_and_returns=0.0137, time/actor_training=185, time/step=458, env/success_once=0.71875, env/return=0.80625, env/episode_len=80.0, env/reward=0.010078125, env/success_at_end=0.625, rollout/rewards=0.0139, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=6.48, rollout/advantages_min=-7.51, rollout/returns_mean=0.524, rollout/returns_max=1.33, rollout/returns_min=-0.875, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0507, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0152, traiGlobal Step:   3%| | 28/1000 [3:40:42<124:07:58, 459.75s/it, time/rollout=273, time/cal_adv_and_returns=0.0137, time/actor_training=185, time/step=458, env/success_once=0.71875, env/return=0.80625, env/episode_len=80.0, env/reward=0.010078125, env/success_at_end=0.625, rollout/rewards=0.0139, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=6.48, rollout/advantages_min=-7.51, rollout/returns_mean=0.524, rollout/returns_max=1.33, rollout/returns_min=-0.875, train/actor/approx_kl=inf, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0507, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0152, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.99s/it]
Global Step:   3%| | 28/1000 [3:48:25<124:07:58, 459.75s/it, time/rollout=274, time/cal_adv_and_returns=0.0134, time/actor_training=189, time/step=463, env/success_once=0.8125, env/return=0.959375, env/episode_len=80.0, env/reward=0.011992188, env/success_at_end=0.78125, rollout/rewards=0.0159, rollout/advantages_mean=0, rollout/advantages_max=6.82, rollout/advantages_min=-5.65, rollout/returns_mean=0.576, rollout/returns_max=1.73, rollout/returns_min=-0.196, train/actor/approx_kl=inf, train/actor/clip_fraction=0.245, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0411, train/actor/ratio=0.985, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00977, train/critic/value_loss=0.0128, train/enGlobal Step:   3%| | 29/1000 [3:48:25<124:16:56, 460.78s/it, time/rollout=274, time/cal_adv_and_returns=0.0134, time/actor_training=189, time/step=463, env/success_once=0.8125, env/return=0.959375, env/episode_len=80.0, env/reward=0.011992188, env/success_at_end=0.78125, rollout/rewards=0.0159, rollout/advantages_mean=0, rollout/advantages_max=6.82, rollout/advantages_min=-5.65, rollout/returns_mean=0.576, rollout/returns_max=1.73, rollout/returns_min=-0.196, train/actor/approx_kl=inf, train/actor/clip_fraction=0.245, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0411, train/actor/ratio=0.985, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00977, train/critic/value_loss=0.0128, train/en[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.10s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.10s/it]
Global Step:   3%| | 29/1000 [3:56:05<124:16:56, 460.78s/it, time/rollout=279, time/cal_adv_and_returns=0.0137, time/actor_training=181, time/step=460, env/success_once=0.8125, env/return=0.959375, env/episode_len=80.0, env/reward=0.011992188, env/success_at_end=0.78125, rollout/rewards=0.0148, rollout/advantages_mean=1.68e-9, rollout/advantages_max=8.06, rollout/advantages_min=-5.79, rollout/returns_mean=0.507, rollout/returns_max=1.31, rollout/returns_min=-0.895, train/actor/approx_kl=inf, train/actor/clip_fraction=0.251, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0642, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.01, traiGlobal Step:   3%| | 30/1000 [3:56:05<124:05:28, 460.55s/it, time/rollout=279, time/cal_adv_and_returns=0.0137, time/actor_training=181, time/step=460, env/success_once=0.8125, env/return=0.959375, env/episode_len=80.0, env/reward=0.011992188, env/success_at_end=0.78125, rollout/rewards=0.0148, rollout/advantages_mean=1.68e-9, rollout/advantages_max=8.06, rollout/advantages_min=-5.79, rollout/returns_mean=0.507, rollout/returns_max=1.31, rollout/returns_min=-0.895, train/actor/approx_kl=inf, train/actor/clip_fraction=0.251, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0642, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.01, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.65s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.65s/it]
Global Step:   3%| | 30/1000 [4:03:44<124:05:28, 460.55s/it, time/rollout=279, time/cal_adv_and_returns=0.0139, time/actor_training=180, time/step=459, env/success_once=0.8125, env/return=0.99375, env/episode_len=80.0, env/reward=0.012421876, env/success_at_end=0.8125, rollout/rewards=0.0158, rollout/advantages_mean=2.24e-9, rollout/advantages_max=9.13, rollout/advantages_min=-6.14, rollout/returns_mean=0.541, rollout/returns_max=1.81, rollout/returns_min=-0.68, train/actor/approx_kl=inf, train/actor/clip_fraction=0.23, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15, train/actor/lr=0.0001, train/actor/policy_loss=0.0816, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00625, train/critic/value_loss=0.0135, train/entGlobal Step:   3%| | 31/1000 [4:03:44<123:48:57, 460.00s/it, time/rollout=279, time/cal_adv_and_returns=0.0139, time/actor_training=180, time/step=459, env/success_once=0.8125, env/return=0.99375, env/episode_len=80.0, env/reward=0.012421876, env/success_at_end=0.8125, rollout/rewards=0.0158, rollout/advantages_mean=2.24e-9, rollout/advantages_max=9.13, rollout/advantages_min=-6.14, rollout/returns_mean=0.541, rollout/returns_max=1.81, rollout/returns_min=-0.68, train/actor/approx_kl=inf, train/actor/clip_fraction=0.23, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15, train/actor/lr=0.0001, train/actor/policy_loss=0.0816, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00625, train/critic/value_loss=0.0135, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.62s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.62s/it]
Global Step:   3%| | 31/1000 [4:11:29<123:48:57, 460.00s/it, time/rollout=280, time/cal_adv_and_returns=0.0134, time/actor_training=185, time/step=465, env/success_once=0.90625, env/return=0.9812499, env/episode_len=80.0, env/reward=0.012265627, env/success_at_end=0.78125, rollout/rewards=0.0155, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=8.36, rollout/advantages_min=-6.83, rollout/returns_mean=0.518, rollout/returns_max=1.67, rollout/returns_min=-0.849, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0618, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0132, Global Step:   3%| | 32/1000 [4:11:29<124:05:33, 461.50s/it, time/rollout=280, time/cal_adv_and_returns=0.0134, time/actor_training=185, time/step=465, env/success_once=0.90625, env/return=0.9812499, env/episode_len=80.0, env/reward=0.012265627, env/success_at_end=0.78125, rollout/rewards=0.0155, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=8.36, rollout/advantages_min=-6.83, rollout/returns_mean=0.518, rollout/returns_max=1.67, rollout/returns_min=-0.849, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0618, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0132, [36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.85s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.85s/it]
Global Step:   3%| | 32/1000 [4:19:11<124:05:33, 461.50s/it, time/rollout=278, time/cal_adv_and_returns=0.0223, time/actor_training=184, time/step=462, env/success_once=0.78125, env/return=0.90312505, env/episode_len=80.0, env/reward=0.011289064, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=-2.24e-9, rollout/advantages_max=7.04, rollout/advantages_min=-5.79, rollout/returns_mean=0.486, rollout/returns_max=1.39, rollout/returns_min=-0.904, train/actor/approx_kl=0.138, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0572, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.012Global Step:   3%| | 33/1000 [4:19:11<124:00:22, 461.66s/it, time/rollout=278, time/cal_adv_and_returns=0.0223, time/actor_training=184, time/step=462, env/success_once=0.78125, env/return=0.90312505, env/episode_len=80.0, env/reward=0.011289064, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=-2.24e-9, rollout/advantages_max=7.04, rollout/advantages_min=-5.79, rollout/returns_mean=0.486, rollout/returns_max=1.39, rollout/returns_min=-0.904, train/actor/approx_kl=0.138, train/actor/clip_fraction=0.25, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0572, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.012[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.41s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.41s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:13:18] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:20:57] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:20:57] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:28:45] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:28:46] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:36:25] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:36:25] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:44:05] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:44:05] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:51:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:51:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/05 [23:59:27] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/05 [23:59:27] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      Global Step:   3%| | 33/1000 [4:26:52<124:00:22, 461.66s/it, time/rollout=275, time/cal_adv_and_returns=0.013, time/actor_training=186, time/step=461, env/success_once=0.75, env/return=0.90312505, env/episode_len=80.0, env/reward=0.011289063, env/success_at_end=0.71875, rollout/rewards=0.0147, rollout/advantages_mean=-1.27e-8, rollout/advantages_max=6.96, rollout/advantages_min=-5.24, rollout/returns_mean=0.49, rollout/returns_max=1.56, rollout/returns_min=-0.755, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0759, train/actor/ratio=1.03, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0133, traiGlobal Step:   3%| | 34/1000 [4:26:52<123:48:27, 461.39s/it, time/rollout=275, time/cal_adv_and_returns=0.013, time/actor_training=186, time/step=461, env/success_once=0.75, env/return=0.90312505, env/episode_len=80.0, env/reward=0.011289063, env/success_at_end=0.71875, rollout/rewards=0.0147, rollout/advantages_mean=-1.27e-8, rollout/advantages_max=6.96, rollout/advantages_min=-5.24, rollout/returns_mean=0.49, rollout/returns_max=1.56, rollout/returns_min=-0.755, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0759, train/actor/ratio=1.03, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0133, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.69s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.69s/it]
Global Step:   3%| | 34/1000 [4:34:36<123:48:27, 461.39s/it, time/rollout=280, time/cal_adv_and_returns=0.0128, time/actor_training=184, time/step=464, env/success_once=0.75, env/return=0.928125, env/episode_len=80.0, env/reward=0.011601563, env/success_at_end=0.75, rollout/rewards=0.0149, rollout/advantages_mean=7.45e-9, rollout/advantages_max=7.34, rollout/advantages_min=-6.61, rollout/returns_mean=0.55, rollout/returns_max=1.27, rollout/returns_min=-0.275, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0617, train/actor/ratio=0.972, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0101, train/enGlobal Step:   4%| | 35/1000 [4:34:36<123:52:00, 462.09s/it, time/rollout=280, time/cal_adv_and_returns=0.0128, time/actor_training=184, time/step=464, env/success_once=0.75, env/return=0.928125, env/episode_len=80.0, env/reward=0.011601563, env/success_at_end=0.75, rollout/rewards=0.0149, rollout/advantages_mean=7.45e-9, rollout/advantages_max=7.34, rollout/advantages_min=-6.61, rollout/returns_mean=0.55, rollout/returns_max=1.27, rollout/returns_min=-0.275, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.969, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0617, train/actor/ratio=0.972, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0101, train/en[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.81s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.81s/it]
Global Step:   4%| | 35/1000 [4:42:19<123:52:00, 462.09s/it, time/rollout=279, time/cal_adv_and_returns=0.014, time/actor_training=184, time/step=463, env/success_once=0.71875, env/return=0.85625005, env/episode_len=80.0, env/reward=0.010703124, env/success_at_end=0.6875, rollout/rewards=0.0152, rollout/advantages_mean=0, rollout/advantages_max=6.15, rollout/advantages_min=-5.44, rollout/returns_mean=0.565, rollout/returns_max=1.64, rollout/returns_min=-0.19, train/actor/approx_kl=0.125, train/actor/clip_fraction=0.217, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0581, train/actor/ratio=1.04, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00273, train/critic/value_loss=0.0121, train/eGlobal Step:   4%| | 36/1000 [4:42:19<123:50:24, 462.47s/it, time/rollout=279, time/cal_adv_and_returns=0.014, time/actor_training=184, time/step=463, env/success_once=0.71875, env/return=0.85625005, env/episode_len=80.0, env/reward=0.010703124, env/success_at_end=0.6875, rollout/rewards=0.0152, rollout/advantages_mean=0, rollout/advantages_max=6.15, rollout/advantages_min=-5.44, rollout/returns_mean=0.565, rollout/returns_max=1.64, rollout/returns_min=-0.19, train/actor/approx_kl=0.125, train/actor/clip_fraction=0.217, train/actor/clipped_ratio=0.967, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0581, train/actor/ratio=1.04, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00273, train/critic/value_loss=0.0121, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.75s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.75s/it]
Global Step:   4%| | 36/1000 [4:50:02<123:50:24, 462.47s/it, time/rollout=279, time/cal_adv_and_returns=0.0105, time/actor_training=184, time/step=463, env/success_once=0.9375, env/return=1.0437499, env/episode_len=80.0, env/reward=0.013046876, env/success_at_end=0.84375, rollout/rewards=0.0166, rollout/advantages_mean=7.82e-9, rollout/advantages_max=7.68, rollout/advantages_min=-7.31, rollout/returns_mean=0.595, rollout/returns_max=1.34, rollout/returns_min=-0.781, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13, train/actor/lr=0.0001, train/actor/policy_loss=0.0574, train/actor/ratio=0.989, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0043, train/critic/value_loss=0.0106, traiGlobal Step:   4%| | 37/1000 [4:50:02<123:45:48, 462.67s/it, time/rollout=279, time/cal_adv_and_returns=0.0105, time/actor_training=184, time/step=463, env/success_once=0.9375, env/return=1.0437499, env/episode_len=80.0, env/reward=0.013046876, env/success_at_end=0.84375, rollout/rewards=0.0166, rollout/advantages_mean=7.82e-9, rollout/advantages_max=7.68, rollout/advantages_min=-7.31, rollout/returns_mean=0.595, rollout/returns_max=1.34, rollout/returns_min=-0.781, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13, train/actor/lr=0.0001, train/actor/policy_loss=0.0574, train/actor/ratio=0.989, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0043, train/critic/value_loss=0.0106, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.90s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.90s/it]
Global Step:   4%| | 37/1000 [4:57:41<123:45:48, 462.67s/it, time/rollout=275, time/cal_adv_and_returns=0.0122, time/actor_training=183, time/step=459, env/success_once=0.875, env/return=0.9625001, env/episode_len=80.0, env/reward=0.01203125, env/success_at_end=0.78125, rollout/rewards=0.016, rollout/advantages_mean=9.69e-9, rollout/advantages_max=6.64, rollout/advantages_min=-6.97, rollout/returns_mean=0.59, rollout/returns_max=1.38, rollout/returns_min=-0.489, train/actor/approx_kl=inf, train/actor/clip_fraction=0.246, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0521, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0114, train/Global Step:   4%| | 38/1000 [4:57:41<123:18:49, 461.47s/it, time/rollout=275, time/cal_adv_and_returns=0.0122, time/actor_training=183, time/step=459, env/success_once=0.875, env/return=0.9625001, env/episode_len=80.0, env/reward=0.01203125, env/success_at_end=0.78125, rollout/rewards=0.016, rollout/advantages_mean=9.69e-9, rollout/advantages_max=6.64, rollout/advantages_min=-6.97, rollout/returns_mean=0.59, rollout/returns_max=1.38, rollout/returns_min=-0.489, train/actor/approx_kl=inf, train/actor/clip_fraction=0.246, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0521, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0114, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.97s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.97s/it]
Global Step:   4%| | 38/1000 [5:05:27<123:18:49, 461.47s/it, time/rollout=282, time/cal_adv_and_returns=0.0114, time/actor_training=184, time/step=466, env/success_once=0.90625, env/return=1.0062499, env/episode_len=80.0, env/reward=0.012578126, env/success_at_end=0.8125, rollout/rewards=0.0165, rollout/advantages_mean=-5.91e-9, rollout/advantages_max=6.03, rollout/advantages_min=-6.35, rollout/returns_mean=0.601, rollout/returns_max=1.68, rollout/returns_min=-0.785, train/actor/approx_kl=inf, train/actor/clip_fraction=0.224, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.4, train/actor/lr=0.0001, train/actor/policy_loss=0.054, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00586, train/critic/value_loss=0.0201, tGlobal Step:   4%| | 39/1000 [5:05:27<123:34:19, 462.91s/it, time/rollout=282, time/cal_adv_and_returns=0.0114, time/actor_training=184, time/step=466, env/success_once=0.90625, env/return=1.0062499, env/episode_len=80.0, env/reward=0.012578126, env/success_at_end=0.8125, rollout/rewards=0.0165, rollout/advantages_mean=-5.91e-9, rollout/advantages_max=6.03, rollout/advantages_min=-6.35, rollout/returns_mean=0.601, rollout/returns_max=1.68, rollout/returns_min=-0.785, train/actor/approx_kl=inf, train/actor/clip_fraction=0.224, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.4, train/actor/lr=0.0001, train/actor/policy_loss=0.054, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00586, train/critic/value_loss=0.0201, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.19s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.19s/it]
[36m(EmbodiedFSDPActor pid=1482199)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
[36m(EmbodiedFSDPActor pid=1482199)[0m   warnings.warn(
[36m(EmbodiedFSDPActor pid=1482201)[0m /home/guo/RL/RLinf/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
[36m(EmbodiedFSDPActor pid=1482201)[0m   warnings.warn(
Global Step:   4%| | 39/1000 [5:17:00<123:34:19, 462.91s/it, time/rollout=279, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=693, env/success_once=0.78125, env/return=0.925, env/episode_len=80.0, env/reward=0.011562501, env/success_at_end=0.75, rollout/rewards=0.0159, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=7.46, rollout/advantages_min=-5.76, rollout/returns_mean=0.588, rollout/returns_max=1.61, rollout/returns_min=-0.0861, train/actor/approx_kl=inf, train/actor/clip_fraction=0.221, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0491, train/actor/ratio=0.977, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0043, train/critic/value_loss=0.0113, train/eGlobal Step:   4%| | 40/1000 [5:17:00<141:52:26, 532.03s/it, time/rollout=279, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=693, env/success_once=0.78125, env/return=0.925, env/episode_len=80.0, env/reward=0.011562501, env/success_at_end=0.75, rollout/rewards=0.0159, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=7.46, rollout/advantages_min=-5.76, rollout/returns_mean=0.588, rollout/returns_max=1.61, rollout/returns_min=-0.0861, train/actor/approx_kl=inf, train/actor/clip_fraction=0.221, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0491, train/actor/ratio=0.977, train/critic/lr=0.003, train/critic/value_clip_ratio=0.0043, train/critic/value_loss=0.0113, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.95s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.95s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:07:13] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:07:13] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:14:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:14:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:22:39] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:22:39] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:30:19] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:30:19] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:38:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:38:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:45:47] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:45:47] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [00:57:24] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [00:57:24] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         Global Step:   4%| | 40/1000 [5:24:49<141:52:26, 532.03s/it, time/rollout=282, time/cal_adv_and_returns=0.0138, time/actor_training=186, time/step=468, env/success_once=0.875, env/return=0.93749994, env/episode_len=80.0, env/reward=0.01171875, env/success_at_end=0.75, rollout/rewards=0.015, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=5.91, rollout/advantages_min=-6.08, rollout/returns_mean=0.534, rollout/returns_max=1.46, rollout/returns_min=-0.74, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17, train/actor/lr=0.0001, train/actor/policy_loss=0.0757, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0162, train/entGlobal Step:   4%| | 41/1000 [5:24:49<136:38:07, 512.92s/it, time/rollout=282, time/cal_adv_and_returns=0.0138, time/actor_training=186, time/step=468, env/success_once=0.875, env/return=0.93749994, env/episode_len=80.0, env/reward=0.01171875, env/success_at_end=0.75, rollout/rewards=0.015, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=5.91, rollout/advantages_min=-6.08, rollout/returns_mean=0.534, rollout/returns_max=1.46, rollout/returns_min=-0.74, train/actor/approx_kl=inf, train/actor/clip_fraction=0.241, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=17, train/actor/lr=0.0001, train/actor/policy_loss=0.0757, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0162, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.04s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.04s/it]
Global Step:   4%| | 41/1000 [5:32:37<136:38:07, 512.92s/it, time/rollout=283, time/cal_adv_and_returns=0.0294, time/actor_training=186, time/step=468, env/success_once=0.90625, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367188, env/success_at_end=0.71875, rollout/rewards=0.0161, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=6.77, rollout/advantages_min=-5.98, rollout/returns_mean=0.581, rollout/returns_max=2.09, rollout/returns_min=-0.506, train/actor/approx_kl=inf, train/actor/clip_fraction=0.229, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0746, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.0229,Global Step:   4%| | 42/1000 [5:32:37<132:55:00, 499.48s/it, time/rollout=283, time/cal_adv_and_returns=0.0294, time/actor_training=186, time/step=468, env/success_once=0.90625, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367188, env/success_at_end=0.71875, rollout/rewards=0.0161, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=6.77, rollout/advantages_min=-5.98, rollout/returns_mean=0.581, rollout/returns_max=2.09, rollout/returns_min=-0.506, train/actor/approx_kl=inf, train/actor/clip_fraction=0.229, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=16.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0746, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.0229,[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.97s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.97s/it]
Global Step:   4%| | 42/1000 [5:40:19<132:55:00, 499.48s/it, time/rollout=278, time/cal_adv_and_returns=0.0125, time/actor_training=184, time/step=462, env/success_once=0.75, env/return=0.859375, env/episode_len=80.0, env/reward=0.010742188, env/success_at_end=0.6875, rollout/rewards=0.0155, rollout/advantages_mean=1.19e-8, rollout/advantages_max=7.17, rollout/advantages_min=-5.36, rollout/returns_mean=0.595, rollout/returns_max=1.47, rollout/returns_min=-0.606, train/actor/approx_kl=inf, train/actor/clip_fraction=0.233, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0641, train/actor/ratio=0.988, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00508, train/critic/value_loss=0.0149, trainGlobal Step:   4%| | 43/1000 [5:40:19<129:47:12, 488.23s/it, time/rollout=278, time/cal_adv_and_returns=0.0125, time/actor_training=184, time/step=462, env/success_once=0.75, env/return=0.859375, env/episode_len=80.0, env/reward=0.010742188, env/success_at_end=0.6875, rollout/rewards=0.0155, rollout/advantages_mean=1.19e-8, rollout/advantages_max=7.17, rollout/advantages_min=-5.36, rollout/returns_mean=0.595, rollout/returns_max=1.47, rollout/returns_min=-0.606, train/actor/approx_kl=inf, train/actor/clip_fraction=0.233, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0641, train/actor/ratio=0.988, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00508, train/critic/value_loss=0.0149, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.06s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.06s/it]
Global Step:   4%| | 43/1000 [5:48:02<129:47:12, 488.23s/it, time/rollout=281, time/cal_adv_and_returns=0.0109, time/actor_training=182, time/step=463, env/success_once=0.875, env/return=0.9312501, env/episode_len=80.0, env/reward=0.011640626, env/success_at_end=0.75, rollout/rewards=0.0155, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=5.84, rollout/advantages_min=-8.45, rollout/returns_mean=0.57, rollout/returns_max=1.39, rollout/returns_min=-0.687, train/actor/approx_kl=inf, train/actor/clip_fraction=0.229, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0462, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0161, train/Global Step:   4%| | 44/1000 [5:48:02<127:39:34, 480.73s/it, time/rollout=281, time/cal_adv_and_returns=0.0109, time/actor_training=182, time/step=463, env/success_once=0.875, env/return=0.9312501, env/episode_len=80.0, env/reward=0.011640626, env/success_at_end=0.75, rollout/rewards=0.0155, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=5.84, rollout/advantages_min=-8.45, rollout/returns_mean=0.57, rollout/returns_max=1.39, rollout/returns_min=-0.687, train/actor/approx_kl=inf, train/actor/clip_fraction=0.229, train/actor/clipped_ratio=0.979, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0462, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0161, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.32s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.32s/it]
Global Step:   4%| | 44/1000 [5:55:44<127:39:34, 480.73s/it, time/rollout=279, time/cal_adv_and_returns=0.0141, time/actor_training=183, time/step=462, env/success_once=0.71875, env/return=0.79999995, env/episode_len=80.0, env/reward=0.010000001, env/success_at_end=0.625, rollout/rewards=0.0136, rollout/advantages_mean=-4.47e-9, rollout/advantages_max=7.44, rollout/advantages_min=-5.02, rollout/returns_mean=0.501, rollout/returns_max=1.28, rollout/returns_min=-0.795, train/actor/approx_kl=inf, train/actor/clip_fraction=0.246, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0734, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0161, tGlobal Step:   4%| | 45/1000 [5:55:44<126:01:17, 475.05s/it, time/rollout=279, time/cal_adv_and_returns=0.0141, time/actor_training=183, time/step=462, env/success_once=0.71875, env/return=0.79999995, env/episode_len=80.0, env/reward=0.010000001, env/success_at_end=0.625, rollout/rewards=0.0136, rollout/advantages_mean=-4.47e-9, rollout/advantages_max=7.44, rollout/advantages_min=-5.02, rollout/returns_mean=0.501, rollout/returns_max=1.28, rollout/returns_min=-0.795, train/actor/approx_kl=inf, train/actor/clip_fraction=0.246, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0734, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0161, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.31s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.31s/it]
Global Step:   4%| | 45/1000 [6:03:23<126:01:17, 475.05s/it, time/rollout=278, time/cal_adv_and_returns=0.0127, time/actor_training=181, time/step=459, env/success_once=0.90625, env/return=1.0749999, env/episode_len=80.0, env/reward=0.0134375, env/success_at_end=0.875, rollout/rewards=0.016, rollout/advantages_mean=-2.05e-9, rollout/advantages_max=6.1, rollout/advantages_min=-5.57, rollout/returns_mean=0.503, rollout/returns_max=1.26, rollout/returns_min=-0.474, train/actor/approx_kl=inf, train/actor/clip_fraction=0.248, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0526, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.0144, train/Global Step:   5%| | 46/1000 [6:03:23<124:35:40, 470.17s/it, time/rollout=278, time/cal_adv_and_returns=0.0127, time/actor_training=181, time/step=459, env/success_once=0.90625, env/return=1.0749999, env/episode_len=80.0, env/reward=0.0134375, env/success_at_end=0.875, rollout/rewards=0.016, rollout/advantages_mean=-2.05e-9, rollout/advantages_max=6.1, rollout/advantages_min=-5.57, rollout/returns_mean=0.503, rollout/returns_max=1.26, rollout/returns_min=-0.474, train/actor/approx_kl=inf, train/actor/clip_fraction=0.248, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.8, train/actor/lr=0.0001, train/actor/policy_loss=0.0526, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.0144, train/[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.54s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.55s/it]
Global Step:   5%| | 46/1000 [6:11:04<124:35:40, 470.17s/it, time/rollout=279, time/cal_adv_and_returns=0.0571, time/actor_training=183, time/step=462, env/success_once=0.875, env/return=0.9406251, env/episode_len=80.0, env/reward=0.011757813, env/success_at_end=0.75, rollout/rewards=0.0152, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=6.33, rollout/advantages_min=-6.24, rollout/returns_mean=0.493, rollout/returns_max=1.66, rollout/returns_min=-0.853, train/actor/approx_kl=inf, train/actor/clip_fraction=0.218, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0446, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0175, traiGlobal Step:   5%| | 47/1000 [6:11:04<123:47:22, 467.62s/it, time/rollout=279, time/cal_adv_and_returns=0.0571, time/actor_training=183, time/step=462, env/success_once=0.875, env/return=0.9406251, env/episode_len=80.0, env/reward=0.011757813, env/success_at_end=0.75, rollout/rewards=0.0152, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=6.33, rollout/advantages_min=-6.24, rollout/returns_mean=0.493, rollout/returns_max=1.66, rollout/returns_min=-0.853, train/actor/approx_kl=inf, train/actor/clip_fraction=0.218, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0446, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0175, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.10s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.10s/it]

[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:05:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:05:13] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:12:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:12:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:20:41] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:20:41] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:28:22] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:28:22] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:36:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:36:03] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:43:43] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:43:43] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:51:26] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:51:26] WARNING  | >> Only support splitting     data_iter_utils.py:159Global Step:   5%| | 47/1000 [6:18:52<123:47:22, 467.62s/it, time/rollout=280, time/cal_adv_and_returns=0.0134, time/actor_training=187, time/step=468, env/success_once=0.90625, env/return=1.096875, env/episode_len=80.0, env/reward=0.013710938, env/success_at_end=0.90625, rollout/rewards=0.016, rollout/advantages_mean=1.12e-9, rollout/advantages_max=6.97, rollout/advantages_min=-5.76, rollout/returns_mean=0.516, rollout/returns_max=1.34, rollout/returns_min=-0.264, train/actor/approx_kl=inf, train/actor/clip_fraction=0.265, train/actor/clipped_ratio=0.966, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0589, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0148, train/entGlobal Step:   5%| | 48/1000 [6:18:52<123:39:11, 467.60s/it, time/rollout=280, time/cal_adv_and_returns=0.0134, time/actor_training=187, time/step=468, env/success_once=0.90625, env/return=1.096875, env/episode_len=80.0, env/reward=0.013710938, env/success_at_end=0.90625, rollout/rewards=0.016, rollout/advantages_mean=1.12e-9, rollout/advantages_max=6.97, rollout/advantages_min=-5.76, rollout/returns_mean=0.516, rollout/returns_max=1.34, rollout/returns_min=-0.264, train/actor/approx_kl=inf, train/actor/clip_fraction=0.265, train/actor/clipped_ratio=0.966, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.4, train/actor/lr=0.0001, train/actor/policy_loss=0.0589, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0148, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.92s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.92s/it]
Global Step:   5%| | 48/1000 [6:26:33<123:39:11, 467.60s/it, time/rollout=279, time/cal_adv_and_returns=0.0102, time/actor_training=182, time/step=461, env/success_once=0.90625, env/return=1.06875, env/episode_len=80.0, env/reward=0.013359376, env/success_at_end=0.875, rollout/rewards=0.0165, rollout/advantages_mean=1.64e-8, rollout/advantages_max=9.06, rollout/advantages_min=-9.02, rollout/returns_mean=0.531, rollout/returns_max=1.46, rollout/returns_min=-0.615, train/actor/approx_kl=inf, train/actor/clip_fraction=0.254, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0637, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0071, train/entrGlobal Step:   5%| | 49/1000 [6:26:33<123:01:54, 465.74s/it, time/rollout=279, time/cal_adv_and_returns=0.0102, time/actor_training=182, time/step=461, env/success_once=0.90625, env/return=1.06875, env/episode_len=80.0, env/reward=0.013359376, env/success_at_end=0.875, rollout/rewards=0.0165, rollout/advantages_mean=1.64e-8, rollout/advantages_max=9.06, rollout/advantages_min=-9.02, rollout/returns_mean=0.531, rollout/returns_max=1.46, rollout/returns_min=-0.615, train/actor/approx_kl=inf, train/actor/clip_fraction=0.254, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0637, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0071, train/entr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.05s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.05s/it]
Global Step:   5%| | 49/1000 [6:34:12<123:01:54, 465.74s/it, time/rollout=275, time/cal_adv_and_returns=0.0136, time/actor_training=183, time/step=459, env/success_once=0.84375, env/return=1.0312501, env/episode_len=80.0, env/reward=0.012890626, env/success_at_end=0.84375, rollout/rewards=0.0159, rollout/advantages_mean=3.73e-9, rollout/advantages_max=8.33, rollout/advantages_min=-5.23, rollout/returns_mean=0.505, rollout/returns_max=1.27, rollout/returns_min=0.0101, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0593, train/actor/ratio=0.992, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0073, Global Step:   5%| | 50/1000 [6:34:12<122:19:50, 463.57s/it, time/rollout=275, time/cal_adv_and_returns=0.0136, time/actor_training=183, time/step=459, env/success_once=0.84375, env/return=1.0312501, env/episode_len=80.0, env/reward=0.012890626, env/success_at_end=0.84375, rollout/rewards=0.0159, rollout/advantages_mean=3.73e-9, rollout/advantages_max=8.33, rollout/advantages_min=-5.23, rollout/returns_mean=0.505, rollout/returns_max=1.27, rollout/returns_min=0.0101, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=14.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0593, train/actor/ratio=0.992, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0073, [36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.72s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.72s/it]
Global Step:   5%| | 50/1000 [6:41:55<122:19:50, 463.57s/it, time/rollout=281, time/cal_adv_and_returns=0.0124, time/actor_training=183, time/step=464, env/success_once=0.875, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367189, env/success_at_end=0.71875, rollout/rewards=0.0147, rollout/advantages_mean=7.45e-9, rollout/advantages_max=5.42, rollout/advantages_min=-7.35, rollout/returns_mean=0.454, rollout/returns_max=1.26, rollout/returns_min=-0.832, train/actor/approx_kl=inf, train/actor/clip_fraction=0.21, train/actor/clipped_ratio=0.98, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=23.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0861, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00938, train/critic/value_loss=0.0181, trainGlobal Step:   5%| | 51/1000 [6:41:55<122:12:11, 463.57s/it, time/rollout=281, time/cal_adv_and_returns=0.0124, time/actor_training=183, time/step=464, env/success_once=0.875, env/return=0.9093751, env/episode_len=80.0, env/reward=0.011367189, env/success_at_end=0.71875, rollout/rewards=0.0147, rollout/advantages_mean=7.45e-9, rollout/advantages_max=5.42, rollout/advantages_min=-7.35, rollout/returns_mean=0.454, rollout/returns_max=1.26, rollout/returns_min=-0.832, train/actor/approx_kl=inf, train/actor/clip_fraction=0.21, train/actor/clipped_ratio=0.98, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=23.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0861, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00938, train/critic/value_loss=0.0181, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.72s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.72s/it]
Global Step:   5%| | 51/1000 [6:49:36<122:12:11, 463.57s/it, time/rollout=279, time/cal_adv_and_returns=0.0117, time/actor_training=182, time/step=461, env/success_once=0.84375, env/return=0.96874994, env/episode_len=80.0, env/reward=0.012109376, env/success_at_end=0.78125, rollout/rewards=0.0148, rollout/advantages_mean=2.38e-8, rollout/advantages_max=6.04, rollout/advantages_min=-6.23, rollout/returns_mean=0.505, rollout/returns_max=1.38, rollout/returns_min=-0.868, train/actor/approx_kl=inf, train/actor/clip_fraction=0.236, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.1, train/actor/lr=0.0001, train/actor/policy_loss=0.0426, train/actor/ratio=0.978, train/critic/lr=0.003, train/critic/value_clip_ratio=0.018, train/critic/value_loss=0.0155, tGlobal Step:   5%| | 52/1000 [6:49:36<121:51:25, 462.75s/it, time/rollout=279, time/cal_adv_and_returns=0.0117, time/actor_training=182, time/step=461, env/success_once=0.84375, env/return=0.96874994, env/episode_len=80.0, env/reward=0.012109376, env/success_at_end=0.78125, rollout/rewards=0.0148, rollout/advantages_mean=2.38e-8, rollout/advantages_max=6.04, rollout/advantages_min=-6.23, rollout/returns_mean=0.505, rollout/returns_max=1.38, rollout/returns_min=-0.868, train/actor/approx_kl=inf, train/actor/clip_fraction=0.236, train/actor/clipped_ratio=0.973, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.1, train/actor/lr=0.0001, train/actor/policy_loss=0.0426, train/actor/ratio=0.978, train/critic/lr=0.003, train/critic/value_clip_ratio=0.018, train/critic/value_loss=0.0155, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 238.00s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 238.00s/it]
Global Step:   5%| | 52/1000 [6:57:16<121:51:25, 462.75s/it, time/rollout=278, time/cal_adv_and_returns=0.0107, time/actor_training=182, time/step=460, env/success_once=0.90625, env/return=1.00625, env/episode_len=80.0, env/reward=0.012578126, env/success_at_end=0.8125, rollout/rewards=0.0152, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=6.03, rollout/advantages_min=-5.4, rollout/returns_mean=0.499, rollout/returns_max=1.41, rollout/returns_min=-0.804, train/actor/approx_kl=inf, train/actor/clip_fraction=0.224, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15, train/actor/lr=0.0001, train/actor/policy_loss=0.0625, train/actor/ratio=0.998, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0204, trainGlobal Step:   5%| | 53/1000 [6:57:16<121:30:59, 461.94s/it, time/rollout=278, time/cal_adv_and_returns=0.0107, time/actor_training=182, time/step=460, env/success_once=0.90625, env/return=1.00625, env/episode_len=80.0, env/reward=0.012578126, env/success_at_end=0.8125, rollout/rewards=0.0152, rollout/advantages_mean=-5.96e-9, rollout/advantages_max=6.03, rollout/advantages_min=-5.4, rollout/returns_mean=0.499, rollout/returns_max=1.41, rollout/returns_min=-0.804, train/actor/approx_kl=inf, train/actor/clip_fraction=0.224, train/actor/clipped_ratio=0.972, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15, train/actor/lr=0.0001, train/actor/policy_loss=0.0625, train/actor/ratio=0.998, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00391, train/critic/value_loss=0.0204, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.35s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.35s/it]
Global Step:   5%| | 53/1000 [7:04:51<121:30:59, 461.94s/it, time/rollout=275, time/cal_adv_and_returns=0.0111, time/actor_training=179, time/step=454, env/success_once=0.75, env/return=0.8968749, env/episode_len=80.0, env/reward=0.011210939, env/success_at_end=0.71875, rollout/rewards=0.0149, rollout/advantages_mean=-1.49e-8, rollout/advantages_max=6.18, rollout/advantages_min=-5.73, rollout/returns_mean=0.515, rollout/returns_max=1.37, rollout/returns_min=-0.321, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0615, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0167, train/entGlobal Step:   5%| | 54/1000 [7:04:51<120:47:24, 459.67s/it, time/rollout=275, time/cal_adv_and_returns=0.0111, time/actor_training=179, time/step=454, env/success_once=0.75, env/return=0.8968749, env/episode_len=80.0, env/reward=0.011210939, env/success_at_end=0.71875, rollout/rewards=0.0149, rollout/advantages_mean=-1.49e-8, rollout/advantages_max=6.18, rollout/advantages_min=-5.73, rollout/returns_mean=0.515, rollout/returns_max=1.37, rollout/returns_min=-0.321, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0615, train/actor/ratio=1.01, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0167, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.46s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:59<00:00, 239.46s/it]

[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [01:59:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [01:59:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:06:50] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:06:50] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:14:34] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:14:34] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:22:15] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:22:15] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:29:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:29:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:37:33] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:37:33] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:45:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         Global Step:   5%| | 54/1000 [7:12:32<120:47:24, 459.67s/it, time/rollout=280, time/cal_adv_and_returns=0.0103, time/actor_training=181, time/step=461, env/success_once=0.75, env/return=0.85625005, env/episode_len=80.0, env/reward=0.010703126, env/success_at_end=0.6875, rollout/rewards=0.0143, rollout/advantages_mean=8.94e-9, rollout/advantages_max=7.16, rollout/advantages_min=-5.7, rollout/returns_mean=0.493, rollout/returns_max=1.23, rollout/returns_min=-0.614, train/actor/approx_kl=inf, train/actor/clip_fraction=0.237, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0511, train/actor/ratio=0.986, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0141, traiGlobal Step:   6%| | 55/1000 [7:12:32<120:46:28, 460.09s/it, time/rollout=280, time/cal_adv_and_returns=0.0103, time/actor_training=181, time/step=461, env/success_once=0.75, env/return=0.85625005, env/episode_len=80.0, env/reward=0.010703126, env/success_at_end=0.6875, rollout/rewards=0.0143, rollout/advantages_mean=8.94e-9, rollout/advantages_max=7.16, rollout/advantages_min=-5.7, rollout/returns_mean=0.493, rollout/returns_max=1.23, rollout/returns_min=-0.614, train/actor/approx_kl=inf, train/actor/clip_fraction=0.237, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=13.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0511, train/actor/ratio=0.986, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0141, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.31s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:01<00:00, 241.31s/it]
Global Step:   6%| | 55/1000 [7:20:18<120:46:28, 460.09s/it, time/rollout=283, time/cal_adv_and_returns=0.0217, time/actor_training=183, time/step=466, env/success_once=0.9375, env/return=0.93437505, env/episode_len=80.0, env/reward=0.0116796885, env/success_at_end=0.78125, rollout/rewards=0.0142, rollout/advantages_mean=1.19e-8, rollout/advantages_max=5.34, rollout/advantages_min=-5.89, rollout/returns_mean=0.466, rollout/returns_max=1.27, rollout/returns_min=-0.926, train/actor/approx_kl=inf, train/actor/clip_fraction=0.226, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0542, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0215, traGlobal Step:   6%| | 56/1000 [7:20:18<121:08:28, 461.98s/it, time/rollout=283, time/cal_adv_and_returns=0.0217, time/actor_training=183, time/step=466, env/success_once=0.9375, env/return=0.93437505, env/episode_len=80.0, env/reward=0.0116796885, env/success_at_end=0.78125, rollout/rewards=0.0142, rollout/advantages_mean=1.19e-8, rollout/advantages_max=5.34, rollout/advantages_min=-5.89, rollout/returns_mean=0.466, rollout/returns_max=1.27, rollout/returns_min=-0.926, train/actor/approx_kl=inf, train/actor/clip_fraction=0.226, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=15.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0542, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0215, tra[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.50s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:54<00:00, 234.50s/it]
Global Step:   6%| | 56/1000 [7:28:03<121:08:28, 461.98s/it, time/rollout=277, time/cal_adv_and_returns=0.0107, time/actor_training=187, time/step=464, env/success_once=0.8125, env/return=0.9968751, env/episode_len=80.0, env/reward=0.012460939, env/success_at_end=0.8125, rollout/rewards=0.0156, rollout/advantages_mean=2.79e-9, rollout/advantages_max=6, rollout/advantages_min=-6.69, rollout/returns_mean=0.517, rollout/returns_max=1.37, rollout/returns_min=-0.286, train/actor/approx_kl=inf, train/actor/clip_fraction=0.239, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0433, train/actor/ratio=0.999, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0148, trainGlobal Step:   6%| | 57/1000 [7:28:03<121:12:38, 462.73s/it, time/rollout=277, time/cal_adv_and_returns=0.0107, time/actor_training=187, time/step=464, env/success_once=0.8125, env/return=0.9968751, env/episode_len=80.0, env/reward=0.012460939, env/success_at_end=0.8125, rollout/rewards=0.0156, rollout/advantages_mean=2.79e-9, rollout/advantages_max=6, rollout/advantages_min=-6.69, rollout/returns_mean=0.517, rollout/returns_max=1.37, rollout/returns_min=-0.286, train/actor/approx_kl=inf, train/actor/clip_fraction=0.239, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0433, train/actor/ratio=0.999, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0148, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.98s/it]
Global Step:   6%| | 57/1000 [7:35:42<121:12:38, 462.73s/it, time/rollout=280, time/cal_adv_and_returns=0.0165, time/actor_training=180, time/step=459, env/success_once=0.71875, env/return=0.84375006, env/episode_len=80.0, env/reward=0.010546875, env/success_at_end=0.6875, rollout/rewards=0.0137, rollout/advantages_mean=2.98e-9, rollout/advantages_max=7.07, rollout/advantages_min=-6.53, rollout/returns_mean=0.487, rollout/returns_max=1.37, rollout/returns_min=-0.532, train/actor/approx_kl=inf, train/actor/clip_fraction=0.237, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0528, train/actor/ratio=0.989, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0106, Global Step:   6%| | 58/1000 [7:35:42<120:49:06, 461.73s/it, time/rollout=280, time/cal_adv_and_returns=0.0165, time/actor_training=180, time/step=459, env/success_once=0.71875, env/return=0.84375006, env/episode_len=80.0, env/reward=0.010546875, env/success_at_end=0.6875, rollout/rewards=0.0137, rollout/advantages_mean=2.98e-9, rollout/advantages_max=7.07, rollout/advantages_min=-6.53, rollout/returns_mean=0.487, rollout/returns_max=1.37, rollout/returns_min=-0.532, train/actor/approx_kl=inf, train/actor/clip_fraction=0.237, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.7, train/actor/lr=0.0001, train/actor/policy_loss=0.0528, train/actor/ratio=0.989, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0106, [36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.43s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.43s/it]
Global Step:   6%| | 58/1000 [7:43:25<120:49:06, 461.73s/it, time/rollout=280, time/cal_adv_and_returns=0.0112, time/actor_training=183, time/step=464, env/success_once=0.78125, env/return=0.896875, env/episode_len=80.0, env/reward=0.011210938, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=-4.47e-9, rollout/advantages_max=6.19, rollout/advantages_min=-7.71, rollout/returns_mean=0.458, rollout/returns_max=1.32, rollout/returns_min=-0.783, train/actor/approx_kl=inf, train/actor/clip_fraction=0.221, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0458, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0127, traiGlobal Step:   6%| | 59/1000 [7:43:25<120:49:56, 462.27s/it, time/rollout=280, time/cal_adv_and_returns=0.0112, time/actor_training=183, time/step=464, env/success_once=0.78125, env/return=0.896875, env/episode_len=80.0, env/reward=0.011210938, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=-4.47e-9, rollout/advantages_max=6.19, rollout/advantages_min=-7.71, rollout/returns_mean=0.458, rollout/returns_max=1.32, rollout/returns_min=-0.783, train/actor/approx_kl=inf, train/actor/clip_fraction=0.221, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0458, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.0127, trai[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.17s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.17s/it]
Global Step:   6%| | 59/1000 [7:51:10<120:49:56, 462.27s/it, time/rollout=282, time/cal_adv_and_returns=0.0135, time/actor_training=182, time/step=464, env/success_once=0.71875, env/return=0.79375005, env/episode_len=80.0, env/reward=0.009921875, env/success_at_end=0.625, rollout/rewards=0.0135, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=5.45, rollout/advantages_min=-4.97, rollout/returns_mean=0.503, rollout/returns_max=1.3, rollout/returns_min=-0.76, train/actor/approx_kl=inf, train/actor/clip_fraction=0.228, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0542, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0172, tGlobal Step:   6%| | 60/1000 [7:51:10<120:51:10, 462.84s/it, time/rollout=282, time/cal_adv_and_returns=0.0135, time/actor_training=182, time/step=464, env/success_once=0.71875, env/return=0.79375005, env/episode_len=80.0, env/reward=0.009921875, env/success_at_end=0.625, rollout/rewards=0.0135, rollout/advantages_mean=-7.45e-9, rollout/advantages_max=5.45, rollout/advantages_min=-4.97, rollout/returns_mean=0.503, rollout/returns_max=1.3, rollout/returns_min=-0.76, train/actor/approx_kl=inf, train/actor/clip_fraction=0.228, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=12.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0542, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0172, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.11s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.11s/it]
Global Step:   6%| | 60/1000 [7:58:52<120:51:10, 462.84s/it, time/rollout=279, time/cal_adv_and_returns=0.0133, time/actor_training=183, time/step=462, env/success_once=0.75, env/return=0.896875, env/episode_len=80.0, env/reward=0.011210938, env/success_at_end=0.75, rollout/rewards=0.0139, rollout/advantages_mean=5.96e-9, rollout/advantages_max=5.86, rollout/advantages_min=-4.58, rollout/returns_mean=0.449, rollout/returns_max=1.29, rollout/returns_min=-0.416, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0541, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0133, train/eGlobal Step:   6%| | 61/1000 [7:58:52<120:40:36, 462.66s/it, time/rollout=279, time/cal_adv_and_returns=0.0133, time/actor_training=183, time/step=462, env/success_once=0.75, env/return=0.896875, env/episode_len=80.0, env/reward=0.011210938, env/success_at_end=0.75, rollout/rewards=0.0139, rollout/advantages_mean=5.96e-9, rollout/advantages_max=5.86, rollout/advantages_min=-4.58, rollout/returns_mean=0.449, rollout/returns_max=1.29, rollout/returns_min=-0.416, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0541, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.0133, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.18s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.18s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:45:12] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [02:52:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [02:52:56] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:00:37] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:00:37] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:08:23] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:08:23] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:16:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:16:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:23:49] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:23:49] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:31:30] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:31:30] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:39:14] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                Global Step:   6%| | 61/1000 [8:06:36<120:40:36, 462.66s/it, time/rollout=281, time/cal_adv_and_returns=0.0133, time/actor_training=183, time/step=464, env/success_once=0.75, env/return=0.9, env/episode_len=80.0, env/reward=0.0112499995, env/success_at_end=0.71875, rollout/rewards=0.0142, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=6.05, rollout/advantages_min=-3.54, rollout/returns_mean=0.472, rollout/returns_max=1.38, rollout/returns_min=-0.2, train/actor/approx_kl=inf, train/actor/clip_fraction=0.214, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11, train/actor/lr=0.0001, train/actor/policy_loss=0.0557, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0121, train/entropy_lGlobal Step:   6%| | 62/1000 [8:06:36<120:38:06, 462.99s/it, time/rollout=281, time/cal_adv_and_returns=0.0133, time/actor_training=183, time/step=464, env/success_once=0.75, env/return=0.9, env/episode_len=80.0, env/reward=0.0112499995, env/success_at_end=0.71875, rollout/rewards=0.0142, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=6.05, rollout/advantages_min=-3.54, rollout/returns_mean=0.472, rollout/returns_max=1.38, rollout/returns_min=-0.2, train/actor/approx_kl=inf, train/actor/clip_fraction=0.214, train/actor/clipped_ratio=0.981, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11, train/actor/lr=0.0001, train/actor/policy_loss=0.0557, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00117, train/critic/value_loss=0.0121, train/entropy_l[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.76s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.76s/it]
Global Step:   6%| | 62/1000 [8:14:24<120:38:06, 462.99s/it, time/rollout=281, time/cal_adv_and_returns=0.013, time/actor_training=187, time/step=468, env/success_once=0.8125, env/return=0.9812499, env/episode_len=80.0, env/reward=0.012265625, env/success_at_end=0.8125, rollout/rewards=0.0145, rollout/advantages_mean=5.4e-9, rollout/advantages_max=6.56, rollout/advantages_min=-4.58, rollout/returns_mean=0.449, rollout/returns_max=1.27, rollout/returns_min=-0.286, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.985, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10, train/actor/lr=0.0001, train/actor/policy_loss=0.039, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.0101, train/entroGlobal Step:   6%| | 63/1000 [8:14:24<120:53:25, 464.47s/it, time/rollout=281, time/cal_adv_and_returns=0.013, time/actor_training=187, time/step=468, env/success_once=0.8125, env/return=0.9812499, env/episode_len=80.0, env/reward=0.012265625, env/success_at_end=0.8125, rollout/rewards=0.0145, rollout/advantages_mean=5.4e-9, rollout/advantages_max=6.56, rollout/advantages_min=-4.58, rollout/returns_mean=0.449, rollout/returns_max=1.27, rollout/returns_min=-0.286, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.985, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10, train/actor/lr=0.0001, train/actor/policy_loss=0.039, train/actor/ratio=1, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.0101, train/entro[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.68s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.68s/it]
Global Step:   6%| | 63/1000 [8:22:10<120:53:25, 464.47s/it, time/rollout=281, time/cal_adv_and_returns=0.0333, time/actor_training=186, time/step=466, env/success_once=0.90625, env/return=1.065625, env/episode_len=80.0, env/reward=0.013320314, env/success_at_end=0.90625, rollout/rewards=0.0155, rollout/advantages_mean=-8.2e-9, rollout/advantages_max=8.07, rollout/advantages_min=-8.19, rollout/returns_mean=0.468, rollout/returns_max=1.34, rollout/returns_min=-0.00243, train/actor/approx_kl=inf, train/actor/clip_fraction=0.234, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0359, train/actor/ratio=0.995, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.00529,Global Step:   6%| | 64/1000 [8:22:10<120:54:36, 465.04s/it, time/rollout=281, time/cal_adv_and_returns=0.0333, time/actor_training=186, time/step=466, env/success_once=0.90625, env/return=1.065625, env/episode_len=80.0, env/reward=0.013320314, env/success_at_end=0.90625, rollout/rewards=0.0155, rollout/advantages_mean=-8.2e-9, rollout/advantages_max=8.07, rollout/advantages_min=-8.19, rollout/returns_mean=0.468, rollout/returns_max=1.34, rollout/returns_min=-0.00243, train/actor/approx_kl=inf, train/actor/clip_fraction=0.234, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0359, train/actor/ratio=0.995, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00234, train/critic/value_loss=0.00529,[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.50s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.50s/it]
Global Step:   6%| | 64/1000 [8:29:55<120:54:36, 465.04s/it, time/rollout=279, time/cal_adv_and_returns=0.0129, time/actor_training=186, time/step=465, env/success_once=0.90625, env/return=0.90937495, env/episode_len=80.0, env/reward=0.011367189, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=9.69e-9, rollout/advantages_max=5.32, rollout/advantages_min=-6.19, rollout/returns_mean=0.502, rollout/returns_max=1.43, rollout/returns_min=-0.921, train/actor/approx_kl=inf, train/actor/clip_fraction=0.2, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0409, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.018, trGlobal Step:   6%| | 65/1000 [8:29:55<120:46:14, 465.00s/it, time/rollout=279, time/cal_adv_and_returns=0.0129, time/actor_training=186, time/step=465, env/success_once=0.90625, env/return=0.90937495, env/episode_len=80.0, env/reward=0.011367189, env/success_at_end=0.71875, rollout/rewards=0.0143, rollout/advantages_mean=9.69e-9, rollout/advantages_max=5.32, rollout/advantages_min=-6.19, rollout/returns_mean=0.502, rollout/returns_max=1.43, rollout/returns_min=-0.921, train/actor/approx_kl=inf, train/actor/clip_fraction=0.2, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.3, train/actor/lr=0.0001, train/actor/policy_loss=0.0409, train/actor/ratio=0.994, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00313, train/critic/value_loss=0.018, tr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.05s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:00<00:00, 240.05s/it]
Global Step:   6%| | 65/1000 [8:37:37<120:46:14, 465.00s/it, time/rollout=281, time/cal_adv_and_returns=0.0106, time/actor_training=181, time/step=462, env/success_once=0.875, env/return=1.034375, env/episode_len=80.0, env/reward=0.012929687, env/success_at_end=0.84375, rollout/rewards=0.0155, rollout/advantages_mean=-1.49e-9, rollout/advantages_max=7.15, rollout/advantages_min=-5.37, rollout/returns_mean=0.501, rollout/returns_max=1.49, rollout/returns_min=-0.743, train/actor/approx_kl=inf, train/actor/clip_fraction=0.191, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0499, train/actor/ratio=0.993, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0137, trGlobal Step:   7%| | 66/1000 [8:37:37<120:26:21, 464.22s/it, time/rollout=281, time/cal_adv_and_returns=0.0106, time/actor_training=181, time/step=462, env/success_once=0.875, env/return=1.034375, env/episode_len=80.0, env/reward=0.012929687, env/success_at_end=0.84375, rollout/rewards=0.0155, rollout/advantages_mean=-1.49e-9, rollout/advantages_max=7.15, rollout/advantages_min=-5.37, rollout/returns_mean=0.501, rollout/returns_max=1.49, rollout/returns_min=-0.743, train/actor/approx_kl=inf, train/actor/clip_fraction=0.191, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.5, train/actor/lr=0.0001, train/actor/policy_loss=0.0499, train/actor/ratio=0.993, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00352, train/critic/value_loss=0.0137, tr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.13s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.13s/it]
Global Step:   7%| | 66/1000 [8:45:20<120:26:21, 464.22s/it, time/rollout=281, time/cal_adv_and_returns=0.0121, time/actor_training=182, time/step=463, env/success_once=0.875, env/return=0.9937501, env/episode_len=80.0, env/reward=0.012421876, env/success_at_end=0.84375, rollout/rewards=0.0152, rollout/advantages_mean=8.2e-9, rollout/advantages_max=7.99, rollout/advantages_min=-3.98, rollout/returns_mean=0.495, rollout/returns_max=1.26, rollout/returns_min=-0.213, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0858, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.00959, traGlobal Step:   7%| | 67/1000 [8:45:20<120:12:41, 463.84s/it, time/rollout=281, time/cal_adv_and_returns=0.0121, time/actor_training=182, time/step=463, env/success_once=0.875, env/return=0.9937501, env/episode_len=80.0, env/reward=0.012421876, env/success_at_end=0.84375, rollout/rewards=0.0152, rollout/advantages_mean=8.2e-9, rollout/advantages_max=7.99, rollout/advantages_min=-3.98, rollout/returns_mean=0.495, rollout/returns_max=1.26, rollout/returns_min=-0.213, train/actor/approx_kl=inf, train/actor/clip_fraction=0.204, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.9, train/actor/lr=0.0001, train/actor/policy_loss=0.0858, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00195, train/critic/value_loss=0.00959, tra[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.78s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.78s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:39:14] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:46:58] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:46:58] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [03:54:46] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [03:54:46] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:02:30] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:02:30] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:10:17] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:10:17] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:18:00] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:18:00] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:25:45] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:25:45] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      Global Step:   7%| | 67/1000 [8:53:08<120:12:41, 463.84s/it, time/rollout=284, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=467, env/success_once=0.90625, env/return=1.059375, env/episode_len=80.0, env/reward=0.013242187, env/success_at_end=0.90625, rollout/rewards=0.0155, rollout/advantages_mean=3.73e-9, rollout/advantages_max=7.43, rollout/advantages_min=-5.59, rollout/returns_mean=0.459, rollout/returns_max=1.6, rollout/returns_min=-0.139, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.34, train/actor/lr=0.0001, train/actor/policy_loss=0.0303, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0106, train/enGlobal Step:   7%| | 68/1000 [8:53:08<120:21:35, 464.91s/it, time/rollout=284, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=467, env/success_once=0.90625, env/return=1.059375, env/episode_len=80.0, env/reward=0.013242187, env/success_at_end=0.90625, rollout/rewards=0.0155, rollout/advantages_mean=3.73e-9, rollout/advantages_max=7.43, rollout/advantages_min=-5.59, rollout/returns_mean=0.459, rollout/returns_max=1.6, rollout/returns_min=-0.139, train/actor/approx_kl=inf, train/actor/clip_fraction=0.223, train/actor/clipped_ratio=0.971, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.34, train/actor/lr=0.0001, train/actor/policy_loss=0.0303, train/actor/ratio=0.991, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0106, train/en[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.64s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:58<00:00, 238.64s/it]
Global Step:   7%| | 68/1000 [9:00:51<120:21:35, 464.91s/it, time/rollout=283, time/cal_adv_and_returns=0.0398, time/actor_training=180, time/step=463, env/success_once=0.875, env/return=1.0, env/episode_len=80.0, env/reward=0.012499999, env/success_at_end=0.8125, rollout/rewards=0.0152, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=7.01, rollout/advantages_min=-7.14, rollout/returns_mean=0.492, rollout/returns_max=1.23, rollout/returns_min=-0.789, train/actor/approx_kl=inf, train/actor/clip_fraction=0.193, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.44, train/actor/lr=0.0001, train/actor/policy_loss=0.0322, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0113, train/eGlobal Step:   7%| | 69/1000 [9:00:51<120:06:21, 464.43s/it, time/rollout=283, time/cal_adv_and_returns=0.0398, time/actor_training=180, time/step=463, env/success_once=0.875, env/return=1.0, env/episode_len=80.0, env/reward=0.012499999, env/success_at_end=0.8125, rollout/rewards=0.0152, rollout/advantages_mean=-2.98e-9, rollout/advantages_max=7.01, rollout/advantages_min=-7.14, rollout/returns_mean=0.492, rollout/returns_max=1.23, rollout/returns_min=-0.789, train/actor/approx_kl=inf, train/actor/clip_fraction=0.193, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.44, train/actor/lr=0.0001, train/actor/policy_loss=0.0322, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0113, train/e[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.81s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:53<00:00, 233.81s/it]
Global Step:   7%| | 69/1000 [9:08:28<120:06:21, 464.43s/it, time/rollout=278, time/cal_adv_and_returns=0.013, time/actor_training=179, time/step=458, env/success_once=0.84375, env/return=1.003125, env/episode_len=80.0, env/reward=0.012539063, env/success_at_end=0.8125, rollout/rewards=0.0153, rollout/advantages_mean=-8.2e-9, rollout/advantages_max=7.84, rollout/advantages_min=-5.88, rollout/returns_mean=0.469, rollout/returns_max=1.41, rollout/returns_min=-0.588, train/actor/approx_kl=inf, train/actor/clip_fraction=0.198, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0323, train/actor/ratio=0.983, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.0107, trGlobal Step:   7%| | 70/1000 [9:08:28<119:26:49, 462.38s/it, time/rollout=278, time/cal_adv_and_returns=0.013, time/actor_training=179, time/step=458, env/success_once=0.84375, env/return=1.003125, env/episode_len=80.0, env/reward=0.012539063, env/success_at_end=0.8125, rollout/rewards=0.0153, rollout/advantages_mean=-8.2e-9, rollout/advantages_max=7.84, rollout/advantages_min=-5.88, rollout/returns_mean=0.469, rollout/returns_max=1.41, rollout/returns_min=-0.588, train/actor/approx_kl=inf, train/actor/clip_fraction=0.198, train/actor/clipped_ratio=0.978, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0323, train/actor/ratio=0.983, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.0107, tr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.86s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.86s/it]
Global Step:   7%| | 70/1000 [9:16:05<119:26:49, 462.38s/it, time/rollout=278, time/cal_adv_and_returns=0.013, time/actor_training=178, time/step=456, env/success_once=0.90625, env/return=1.0437499, env/episode_len=80.0, env/reward=0.013046876, env/success_at_end=0.84375, rollout/rewards=0.0156, rollout/advantages_mean=4.1e-9, rollout/advantages_max=8.08, rollout/advantages_min=-7.98, rollout/returns_mean=0.475, rollout/returns_max=1.41, rollout/returns_min=-0.763, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.7, train/actor/lr=0.0001, train/actor/policy_loss=0.047, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0108, train/entGlobal Step:   7%| | 71/1000 [9:16:05<118:49:55, 460.49s/it, time/rollout=278, time/cal_adv_and_returns=0.013, time/actor_training=178, time/step=456, env/success_once=0.90625, env/return=1.0437499, env/episode_len=80.0, env/reward=0.013046876, env/success_at_end=0.84375, rollout/rewards=0.0156, rollout/advantages_mean=4.1e-9, rollout/advantages_max=8.08, rollout/advantages_min=-7.98, rollout/returns_mean=0.475, rollout/returns_max=1.41, rollout/returns_min=-0.763, train/actor/approx_kl=inf, train/actor/clip_fraction=0.208, train/actor/clipped_ratio=0.976, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.7, train/actor/lr=0.0001, train/actor/policy_loss=0.047, train/actor/ratio=0.996, train/critic/lr=0.003, train/critic/value_clip_ratio=0, train/critic/value_loss=0.0108, train/ent[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.89s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.89s/it]
Global Step:   7%| | 71/1000 [9:23:44<118:49:55, 460.49s/it, time/rollout=281, time/cal_adv_and_returns=0.0101, time/actor_training=179, time/step=460, env/success_once=0.78125, env/return=0.96875, env/episode_len=80.0, env/reward=0.012109375, env/success_at_end=0.78125, rollout/rewards=0.0143, rollout/advantages_mean=-1.68e-8, rollout/advantages_max=9.54, rollout/advantages_min=-3.99, rollout/returns_mean=0.461, rollout/returns_max=1.34, rollout/returns_min=-0.128, train/actor/approx_kl=inf, train/actor/clip_fraction=0.201, train/actor/clipped_ratio=0.98, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.69, train/actor/lr=0.0001, train/actor/policy_loss=0.0389, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.0105, tGlobal Step:   7%| | 72/1000 [9:23:44<118:39:36, 460.32s/it, time/rollout=281, time/cal_adv_and_returns=0.0101, time/actor_training=179, time/step=460, env/success_once=0.78125, env/return=0.96875, env/episode_len=80.0, env/reward=0.012109375, env/success_at_end=0.78125, rollout/rewards=0.0143, rollout/advantages_mean=-1.68e-8, rollout/advantages_max=9.54, rollout/advantages_min=-3.99, rollout/returns_mean=0.461, rollout/returns_max=1.34, rollout/returns_min=-0.128, train/actor/approx_kl=inf, train/actor/clip_fraction=0.201, train/actor/clipped_ratio=0.98, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.69, train/actor/lr=0.0001, train/actor/policy_loss=0.0389, train/actor/ratio=0.982, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.0105, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.76s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:55<00:00, 235.76s/it]
Global Step:   7%| | 72/1000 [9:31:24<118:39:36, 460.32s/it, time/rollout=279, time/cal_adv_and_returns=0.0107, time/actor_training=181, time/step=460, env/success_once=0.84375, env/return=1.0031251, env/episode_len=80.0, env/reward=0.012539064, env/success_at_end=0.8125, rollout/rewards=0.015, rollout/advantages_mean=-2.01e-8, rollout/advantages_max=10.2, rollout/advantages_min=-5.71, rollout/returns_mean=0.463, rollout/returns_max=1.15, rollout/returns_min=-0.638, train/actor/approx_kl=inf, train/actor/clip_fraction=0.206, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.1, train/actor/lr=0.0001, train/actor/policy_loss=0.047, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.00763, tGlobal Step:   7%| | 73/1000 [9:31:24<118:28:39, 460.11s/it, time/rollout=279, time/cal_adv_and_returns=0.0107, time/actor_training=181, time/step=460, env/success_once=0.84375, env/return=1.0031251, env/episode_len=80.0, env/reward=0.012539064, env/success_at_end=0.8125, rollout/rewards=0.015, rollout/advantages_mean=-2.01e-8, rollout/advantages_max=10.2, rollout/advantages_min=-5.71, rollout/returns_mean=0.463, rollout/returns_max=1.15, rollout/returns_min=-0.638, train/actor/approx_kl=inf, train/actor/clip_fraction=0.206, train/actor/clipped_ratio=0.975, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=11.1, train/actor/lr=0.0001, train/actor/policy_loss=0.047, train/actor/ratio=1.02, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.00763, t[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.56s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:56<00:00, 236.56s/it]
Global Step:   7%| | 73/1000 [9:39:04<118:28:39, 460.11s/it, time/rollout=278, time/cal_adv_and_returns=0.0188, time/actor_training=182, time/step=460, env/success_once=0.90625, env/return=1.0749999, env/episode_len=80.0, env/reward=0.013437501, env/success_at_end=0.875, rollout/rewards=0.0155, rollout/advantages_mean=1.86e-9, rollout/advantages_max=6.88, rollout/advantages_min=-6.26, rollout/returns_mean=0.457, rollout/returns_max=1.24, rollout/returns_min=-0.81, train/actor/approx_kl=inf, train/actor/clip_fraction=0.207, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0401, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0106, trGlobal Step:   7%| | 74/1000 [9:39:04<118:18:34, 459.95s/it, time/rollout=278, time/cal_adv_and_returns=0.0188, time/actor_training=182, time/step=460, env/success_once=0.90625, env/return=1.0749999, env/episode_len=80.0, env/reward=0.013437501, env/success_at_end=0.875, rollout/rewards=0.0155, rollout/advantages_mean=1.86e-9, rollout/advantages_max=6.88, rollout/advantages_min=-6.26, rollout/returns_mean=0.457, rollout/returns_max=1.24, rollout/returns_min=-0.81, train/actor/approx_kl=inf, train/actor/clip_fraction=0.207, train/actor/clipped_ratio=0.977, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=10.2, train/actor/lr=0.0001, train/actor/policy_loss=0.0401, train/actor/ratio=0.997, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000781, train/critic/value_loss=0.0106, tr[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.17s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.17s/it]

[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:33:32] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:33:32] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:41:10] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:41:10] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:48:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:48:48] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [04:56:27] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [04:56:27] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [05:04:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [05:04:04] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [05:11:43] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [05:11:43] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482201)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482199)[0m 11/06 [05:19:21] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482199)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482199)[0m                           Discarding the following keys                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           from the batch: ['loss_mask',                         
[36m(EmbodiedFSDPActor pid=1482199)[0m                           'loss_mask_sum']                                      
[36m(EmbodiedFSDPActor pid=1482201)[0m 11/06 [05:19:21] WARNING  | >> Only support splitting     data_iter_utils.py:159
[36m(EmbodiedFSDPActor pid=1482201)[0m                           torch.Tensor and List.                                
[36m(EmbodiedFSDPActor pid=1482201)[0m                           Discarding the following keys                         Global Step:   7%| | 74/1000 [9:46:44<118:18:34, 459.95s/it, time/rollout=276, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=460, env/success_once=0.75, env/return=0.94062495, env/episode_len=80.0, env/reward=0.011757813, env/success_at_end=0.75, rollout/rewards=0.0147, rollout/advantages_mean=8.2e-9, rollout/advantages_max=8.18, rollout/advantages_min=-4.24, rollout/returns_mean=0.472, rollout/returns_max=1.4, rollout/returns_min=-0.0922, train/actor/approx_kl=inf, train/actor/clip_fraction=0.247, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.01, train/actor/lr=0.0001, train/actor/policy_loss=0.0414, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.00782, trainGlobal Step:   8%| | 75/1000 [9:46:44<118:11:31, 459.99s/it, time/rollout=276, time/cal_adv_and_returns=0.0116, time/actor_training=184, time/step=460, env/success_once=0.75, env/return=0.94062495, env/episode_len=80.0, env/reward=0.011757813, env/success_at_end=0.75, rollout/rewards=0.0147, rollout/advantages_mean=8.2e-9, rollout/advantages_max=8.18, rollout/advantages_min=-4.24, rollout/returns_mean=0.472, rollout/returns_max=1.4, rollout/returns_min=-0.0922, train/actor/approx_kl=inf, train/actor/clip_fraction=0.247, train/actor/clipped_ratio=0.97, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.01, train/actor/lr=0.0001, train/actor/policy_loss=0.0414, train/actor/ratio=0.987, train/critic/lr=0.003, train/critic/value_clip_ratio=0.000391, train/critic/value_loss=0.00782, train[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
[36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.55s/it]Generating Rollout Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:57<00:00, 237.55s/it]
Global Step:   8%| | 75/1000 [9:54:25<118:11:31, 459.99s/it, time/rollout=279, time/cal_adv_and_returns=0.0392, time/actor_training=183, time/step=461, env/success_once=0.8125, env/return=0.9656249, env/episode_len=80.0, env/reward=0.012070313, env/success_at_end=0.78125, rollout/rewards=0.0142, rollout/advantages_mean=-6.71e-9, rollout/advantages_max=7.57, rollout/advantages_min=-5.31, rollout/returns_mean=0.423, rollout/returns_max=1.15, rollout/returns_min=-0.605, train/actor/approx_kl=inf, train/actor/clip_fraction=0.218, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0457, train/actor/ratio=0.975, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.00921, Global Step:   8%| | 76/1000 [9:54:25<118:09:49, 460.38s/it, time/rollout=279, time/cal_adv_and_returns=0.0392, time/actor_training=183, time/step=461, env/success_once=0.8125, env/return=0.9656249, env/episode_len=80.0, env/reward=0.012070313, env/success_at_end=0.78125, rollout/rewards=0.0142, rollout/advantages_mean=-6.71e-9, rollout/advantages_max=7.57, rollout/advantages_min=-5.31, rollout/returns_mean=0.423, rollout/returns_max=1.15, rollout/returns_min=-0.605, train/actor/approx_kl=inf, train/actor/clip_fraction=0.218, train/actor/clipped_ratio=0.974, train/actor/dual_cliped_ratio=0, train/actor/grad_norm=9.6, train/actor/lr=0.0001, train/actor/policy_loss=0.0457, train/actor/ratio=0.975, train/critic/lr=0.003, train/critic/value_clip_ratio=0.00156, train/critic/value_loss=0.00921, [36m(MultiStepRolloutWorker pid=1482202)[0m Generating Rollout Epochs:   0%|          | 0/1 [00:00<?, ?it/s]
